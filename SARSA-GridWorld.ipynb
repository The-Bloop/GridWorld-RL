{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pmasilam_sabariis_assignment4_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\"I (We) certify that the code and data in this assignment were generated independently,\n",
        "using only the tools and resources defined in the course and that I (we) did not receive\n",
        "any external help, coaching or contributions during the production of this work.\"\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "mvx3k3fCN91X",
        "outputId": "12b1f66c-5a88-4a7b-e2ea-022d1a8322e2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\"I (We) certify that the code and data in this assignment were generated independently,\\nusing only the tools and resources defined in the course and that I (we) did not receive\\nany external help, coaching or contributions during the production of this work.\"\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ2NIWY_VqBq",
        "outputId": "f7c94241-aae1-47de-9d2f-18e512ddcc8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.21.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gym"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gym\n",
        "from gym import spaces"
      ],
      "metadata": {
        "id": "9j4Qb7nU6RuC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid = np.zeros((4, 4))\n",
        "print(grid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q2ods0l6b-2",
        "outputId": "e6b3cdde-7d78-4051-c82b-5c77faa838f5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos1 = [3, 0]\n",
        "pos2 = [3, 2]\n",
        "pos3 = [2, 3]\n",
        "pos4 = [0, 0]\n",
        "pos5 = [0, 2]\n",
        "pos6 = [0, 3]\n",
        "\n",
        "\n",
        "\n",
        "grid[tuple(pos1)] = 1   #Initial Postion\n",
        "grid[tuple(pos2)] = 0.3  #Negative Reward - Rock\n",
        "grid[tuple(pos3)] = 0.3  #Negative Reward - Rock\n",
        "grid[tuple(pos4)] = 0.7     #Positive Reward - Battery\n",
        "grid[tuple(pos5)] = 0.7     #Positive Reward - Battery\n",
        "grid[tuple(pos6)] = 0.9     #GOALLLL\n",
        "\n",
        "\n",
        "print(grid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuUnFoP26iA0",
        "outputId": "d3758ab3-0a9a-49b3-9768-c40e5dd39d6d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(grid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "Dm-hGSkw6r82",
        "outputId": "70c091c5-d4ef-4534-dc3e-10b1e128cc87"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe93dd6b510>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GridEnvironment(gym.Env):\n",
        "  metadata = { 'render.modes': []}\n",
        "\n",
        "  def __init__(self):\n",
        "    self.observation_space = spaces.Discrete(9)\n",
        "    self.action_space = spaces.Discrete(4)\n",
        "    self.max_timesteps = 12\n",
        "    self.reward = 0\n",
        "    self.immediate_reward = 0\n",
        "\n",
        "  def reset(self):\n",
        "    self.reward = 0\n",
        "    self.immediate_reward = 0\n",
        "    self.timestep = 0\n",
        "    x = np.random.randint(0,3)\n",
        "    y = np.random.randint(0,3)\n",
        "    self.agent_pos = [x, y]\n",
        "    while(self.agent_pos[0] == 0 and self.agent_pos[1] == 3):\n",
        "      x = np.random.randint(0,3)\n",
        "      y = np.random.randint(0,3)\n",
        "      self.agent_pos = [x, y]\n",
        "    self.goal_pos = [0, 3]\n",
        "    self.negative_reward_position1 = [3, 2]\n",
        "    self.negative_reward_position2 = [2, 3]\n",
        "    self.positive_reward_position1 = [0, 0]\n",
        "    self.positive_reward_position2 = [0, 2]\n",
        "    self.state = np.zeros((4, 4))\n",
        "    self.state[tuple(self.agent_pos)] = 1\n",
        "    self.state[tuple(self.goal_pos)] = 0.9\n",
        "    self.state[tuple(self.negative_reward_position1)] = 0.3\n",
        "    self.state[tuple(self.negative_reward_position2)] = 0.3\n",
        "    self.state[tuple(self.positive_reward_position1)] = 0.7\n",
        "    self.state[tuple(self.positive_reward_position2)] = 0.7\n",
        "    observation = self.state.flatten()\n",
        "    print(self.state)\n",
        "    return observation\n",
        "\n",
        "  def getAvailableActions(self):\n",
        "    actions = []\n",
        "    if(self.agent_pos[0] < 3):\n",
        "      actions.append(0)\n",
        "    if(self.agent_pos[0] > 0):\n",
        "      actions.append(1)\n",
        "    if(self.agent_pos[1] < 3):\n",
        "      actions.append(2)\n",
        "    if(self.agent_pos[1] > 0):\n",
        "      actions.append(3)\n",
        "    return actions\n",
        "\n",
        "    # 0 = down\n",
        "    # 1 = up\n",
        "    # 2 = right\n",
        "    # 3 = left\n",
        "\n",
        "  def step(self, action):\n",
        "    self.state = np.random.choice(self.observation_space.n)\n",
        "    if action == 0 and self.agent_pos[0] < 3:\n",
        "      self.agent_pos[0] += 1\n",
        "    if action == 1 and self.agent_pos[0] > 0:\n",
        "      self.agent_pos[0] -= 1\n",
        "    if action == 2 and self.agent_pos[1] < 3:\n",
        "      self.agent_pos[1] += 1\n",
        "    if action == 3 and self.agent_pos[1] > 0:\n",
        "      self.agent_pos[1] -= 1\n",
        "    \n",
        "    self.agent_pos = np.clip(self.agent_pos, 0, 3)\n",
        "    print(\"The Agent state is\", self.agent_pos)\n",
        "    self.state = np.zeros((4,4))\n",
        "    self.state[tuple(self.agent_pos)] = 1\n",
        "    self.state[tuple(self.goal_pos)] = 0.9\n",
        "    self.state[tuple(self.negative_reward_position1)] = 0.3\n",
        "    self.state[tuple(self.negative_reward_position2)] = 0.3\n",
        "    self.state[tuple(self.positive_reward_position1)] = 0.7\n",
        "    self.state[tuple(self.positive_reward_position2)] = 0.7\n",
        "    observation = self.state.flatten()\n",
        "\n",
        "    done = False\n",
        "    if (self.agent_pos == self.negative_reward_position1).all():\n",
        "      self.immediate_reward = -5\n",
        "      # self.reward = -5 + self.reward\n",
        "    elif (self.agent_pos == self.negative_reward_position2).all():\n",
        "      self.immediate_reward = -6\n",
        "      # self.reward = -6 + self.reward\n",
        "    elif (self.agent_pos == self.positive_reward_position1).all():\n",
        "      self.immediate_reward = 5\n",
        "      # self.reward = 5 + self.reward\n",
        "    elif (self.agent_pos == self.positive_reward_position2).all():\n",
        "      self.immediate_reward = 6\n",
        "      # self.reward = 6 + self.reward\n",
        "    elif (self.agent_pos == self.goal_pos).all():\n",
        "      self.immediate_reward = 50\n",
        "      # self.reward = 50 + self.reward\n",
        "      done = True\n",
        "    else:\n",
        "      self.immediate_reward = 0.5\n",
        "      # self.reward = 0.1 + self.reward\n",
        "    self.reward = self.immediate_reward + self.reward\n",
        "\n",
        "    self.timestep += 1\n",
        "    # done = True if self.agent_pos[0] == 0 and self.agent_pos[0] == 3 else False\n",
        "    info = {}\n",
        "    print(self.state)\n",
        "\n",
        "    return observation, self.reward, done, info\n",
        "\n",
        "  def render(self):\n",
        "    plt.imshow(self.state)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "UM3-Q6zv68Ib"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from traitlets.traitlets import observe\n",
        "env = GridEnvironment()\n",
        "obs = env.reset()\n",
        "env.render()\n",
        "print(obs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "8Rk7dsV99XZ2",
        "outputId": "0e437c6e-81b2-4a74-d8f5-a4e091898f69"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7 0.  0.7 0.9 0.  0.  0.  0.  0.  0.  0.  0.3 0.  0.  0.3 0. ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RANDOM AGENT FOR 10 TIMESTEPS\n",
        "random_agent = list(range(0,4))\n",
        "\n",
        "for i in range(10):\n",
        "  action = np.random.choice(random_agent)\n",
        "  observation, reward, done, _ = env.step(action)\n",
        "  print('Reward: ', reward)\n",
        "  print('Action: ', action)\n",
        "  print(\"Visualization Graph\")\n",
        "  env.render()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0-Y6GL-RIJWT",
        "outputId": "ccd8ffe1-0f1c-4d0f-cd12-c967f563f443"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  50\n",
            "Action:  2\n",
            "Visualization Graph\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  50.5\n",
            "Action:  0\n",
            "Visualization Graph\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  51.0\n",
            "Action:  3\n",
            "Visualization Graph\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  51.5\n",
            "Action:  3\n",
            "Visualization Graph\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  52.0\n",
            "Action:  2\n",
            "Visualization Graph\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  52.5\n",
            "Action:  0\n",
            "Visualization Graph\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  46.5\n",
            "Action:  2\n",
            "Visualization Graph\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  40.5\n",
            "Action:  2\n",
            "Visualization Graph\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  34.5\n",
            "Action:  2\n",
            "Visualization Graph\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  35.0\n",
            "Action:  3\n",
            "Visualization Graph\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Because of overlapping of 2 colors in action, the grid color may change sometimes"
      ],
      "metadata": {
        "id": "WOjJg2lXOOae"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART II"
      ],
      "metadata": {
        "id": "tOFqPW3GQEfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SARSA_Agent():\n",
        "  def __init__(self, env, gamma = 1, alpha = 0.01, epsilon = 0.2):\n",
        "    self.env = env\n",
        "    self.gamma = gamma\n",
        "    self.epsilon = epsilon\n",
        "    self.alpha = alpha\n",
        "\n",
        "    self.q_table = dict()\n",
        "    for i in range(4):\n",
        "      for j in range(4):\n",
        "        self.q_table[(i,j)] = {0:0, 1:0, 2:0, 3:0}\n",
        "    self.value_table = np.zeros((4,4))\n",
        "\n",
        "  def ChooseAction(self, learn_flag):\n",
        "    actions = self.env.getAvailableActions()\n",
        "    action = -1;\n",
        "    eps = -1\n",
        "    if(learn_flag == True):\n",
        "      eps = self.epsilon\n",
        "    if(np.random.uniform(0,1) < eps):\n",
        "      print('Random Action')\n",
        "      action = actions[np.random.randint(0,len(actions))]\n",
        "    else:\n",
        "      print('Greedy Action')\n",
        "      q_values = np.array(list(self.q_table[tuple(self.env.agent_pos)].values()))\n",
        "      available_q_values = []\n",
        "      for i in actions:\n",
        "        available_q_values.append(q_values[i])\n",
        "      max_q_value = max(available_q_values)\n",
        "      inds = np.where((np.array(available_q_values))== max_q_value)\n",
        "      indexes = inds[0]\n",
        "      action = actions[indexes[np.random.randint(0,len(indexes))]]\n",
        "    return action\n",
        "\n",
        "  def Learn(self, old_state, old_action, reward, new_state, new_action):\n",
        "    old_state_q = (self.q_table[tuple(old_state)])\n",
        "    old_q = old_state_q[old_action]\n",
        "      \n",
        "    new_state_q = (self.q_table[tuple(new_state)])\n",
        "    new_q = new_state_q[new_action]\n",
        "\n",
        "    self.q_table[tuple(old_state)][old_action] = old_q + (self.alpha * (reward + (self.gamma * new_q) - old_q))\n",
        "    self.value_table[old_state[0]][old_state[1]] = max(self.q_table[tuple(old_state)].values())\n",
        "\n",
        "  def reset(self):\n",
        "    self.env.reset()\n"
      ],
      "metadata": {
        "id": "dLqk68ncQH7P"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = SARSA_Agent(env, gamma=0.1, epsilon= 0.2, alpha = 0.0001)#0.4,0.8,0.01\n",
        "reward_per_episode = []\n",
        "obs = agent.reset()\n",
        "for j in range(500):\n",
        "  obs = agent.reset()\n",
        "  # x = np.random.randint(0,3)\n",
        "  # y = np.random.randint(0,3)\n",
        "  # env.agent_pos = [x,y]\n",
        "  # while(env.agent_pos[0] == 0 and env.agent_pos[1] == 3):\n",
        "  #   x = np.random.randint(0,3)\n",
        "  #   y = np.random.randint(0,3)\n",
        "  #   env.agent_pos = [x,y]\n",
        "  done = False\n",
        "  action = agent.ChooseAction(True)\n",
        "  cummulative_reward = 0\n",
        "  for i in range(15):\n",
        "    if(done == False):\n",
        "      old_state = env.agent_pos\n",
        "      observation, reward, done, _ = env.step(action)\n",
        "      new_state = env.agent_pos\n",
        "      new_action = agent.ChooseAction(True)\n",
        "      agent.Learn(old_state, action, env.immediate_reward, new_state, new_action)\n",
        "      action = new_action\n",
        "      cummulative_reward = reward\n",
        "      if(done == True):\n",
        "        print('Reward: ', env.immediate_reward)\n",
        "        print('Action: ', action)\n",
        "        print(\"Visualization Graph\")\n",
        "  reward_per_episode.append(cummulative_reward)\n",
        "\n",
        "plt.plot(reward_per_episode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "73ctfPbTYdKY",
        "outputId": "490dde01-ba16-45d9-a7a4-f818739dc9b9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe93d623910>]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_reward_per_episode = []\n",
        "for i in range(0,10):\n",
        "  print(\"New Episode!\")\n",
        "  agent.reset()\n",
        "  done = False\n",
        "  for j in range(0,25):\n",
        "    if(done == False):\n",
        "      print('Available Actions : ', env.getAvailableActions())\n",
        "      action = agent.ChooseAction(False)\n",
        "      observation, reward, done, _ = env.step(action)\n",
        "      print('Reward: ', reward)\n",
        "      # print('Action: ', action)\n",
        "      # print(\"Visualization Graph\")\n",
        "      # env.render()\n",
        "    else:\n",
        "      print('Goal Reached')\n",
        "      break\n",
        "    print(done)\n",
        "  total_reward_per_episode.append(reward)\n",
        "plt.plot(total_reward_per_episode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EbDSrV9onp_i",
        "outputId": "72a874c3-7153-40cb-c188-de2a56c0aea1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Reward:  1.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -2.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  3.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  53.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Reward:  1.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -2.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  3.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  53.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  1.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  2.0\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Reward:  2.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -2.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -2.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -1.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  4.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  54.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Reward:  1.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -2.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  3.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  53.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56.5\n",
            "True\n",
            "Goal Reached\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe93d549450>]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent.q_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMj99jD9axF2",
        "outputId": "d085b644-74f0-4da2-af34-54b82828f079"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(0, 0): {0: 0, 1: 0.11320452121643178, 2: 0, 3: 0.00949145484306258}, (0, 1): {0: 0, 1: 0.00015004130014606516, 2: 0.006807628062132694, 3: 0.0009996164552469806}, (0, 2): {0: 0, 1: 0.05025192663215556, 2: 0.1024002376882791, 3: 0}, (0, 3): {0: 0, 1: 0.8821695073380059, 2: 1.2979224014159476, 3: 0}, (1, 0): {0: 0.008336905384924166, 1: 0.008287717404600983, 2: 0, 3: 0.00030020252114272875}, (1, 1): {0: 0.0006497050276619499, 1: 0.0002499854764927557, 2: 0.001298532562926363, 3: 0.0008494855799101522}, (1, 2): {0: 0.0010496638152391296, 1: 0.006462809822132057, 2: 0.0055224078684880835, 3: 0.0006998342718057712}, (1, 3): {0: 0, 1: 0.000149986500405, 2: 0.01009728018448585, 3: 0}, (2, 0): {0: 0.006412632747186144, 1: 0.006165715662286427, 2: 0, 3: 0.0058685511756657}, (2, 1): {0: 0.0001500154563021947, 1: 0.0006997372955980142, 2: 0.0014483608451599668, 3: 0.0018967885299721197}, (2, 2): {0: 0.000899560432329091, 1: 0.00443224251755748, 2: 0.0005497755366235467, 3: 0.0012987024465687862}, (2, 3): {0: -0.00839462613187718, 1: -0.004798386277124569, 2: -0.006596748964068506, 3: 0}, (3, 0): {0: 0.01127157927957114, 1: 0, 2: 0, 3: 0.0012983762992528286}, (3, 1): {0: 0.0002499804617442735, 1: 0, 2: 0.006264043301121534, 3: 0.0011490675689741054}, (3, 2): {0: -0.004498200419937007, 1: 0, 2: -0.056683799611734725, 3: -0.004498200419937007}, (3, 3): {0: 0.0001499850005, 1: 0, 2: 0.0007494752274317649, 3: 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent.value_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cry1aaZXZa97",
        "outputId": "c0e93a4d-938f-421f-f291-ca820a0f601d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.13204521e-01 6.80762806e-03 1.02400238e-01 1.29792240e+00]\n",
            " [8.33690538e-03 1.29853256e-03 6.46280982e-03 1.00972802e-02]\n",
            " [6.41263275e-03 1.89678853e-03 4.43224252e-03 0.00000000e+00]\n",
            " [1.12715793e-02 6.26404330e-03 0.00000000e+00 7.49475227e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper Parameter 1: \n",
        "Gamma Value: 0.2\n",
        "\n"
      ],
      "metadata": {
        "id": "Wp04saJJSnFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = SARSA_Agent(env, gamma=0.2, epsilon= 0.2, alpha = 0.0001)#0.4,0.8,0.01\n",
        "reward_per_episode = []\n",
        "obs = agent.reset()\n",
        "for j in range(500):\n",
        "  obs = agent.reset()\n",
        "  # x = np.random.randint(0,3)\n",
        "  # y = np.random.randint(0,3)\n",
        "  # env.agent_pos = [x,y]\n",
        "  # while(env.agent_pos[0] == 0 and env.agent_pos[1] == 3):\n",
        "  #   x = np.random.randint(0,3)\n",
        "  #   y = np.random.randint(0,3)\n",
        "  #   env.agent_pos = [x,y]\n",
        "  done = False\n",
        "  action = agent.ChooseAction(True)\n",
        "  cummulative_reward = 0\n",
        "  for i in range(15):\n",
        "    if(done == False):\n",
        "      old_state = env.agent_pos\n",
        "      observation, reward, done, _ = env.step(action)\n",
        "      new_state = env.agent_pos\n",
        "      new_action = agent.ChooseAction(True)\n",
        "      agent.Learn(old_state, action, env.immediate_reward, new_state, new_action)\n",
        "      action = new_action\n",
        "      cummulative_reward = reward\n",
        "      if(done == True):\n",
        "        print('Reward: ', env.immediate_reward)\n",
        "        print('Action: ', action)\n",
        "        print(\"Visualization Graph\")\n",
        "  reward_per_episode.append(cummulative_reward)\n",
        "\n",
        "plt.plot(reward_per_episode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tFShjX9NTOjX",
        "outputId": "a739b8b7-b826-4ce3-8ec6-630b1486231d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe93d6e7b10>]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_reward_per_episode = []\n",
        "for i in range(0,10):\n",
        "  print(\"New Episode!\")\n",
        "  agent.reset()\n",
        "  done = False\n",
        "  for j in range(0,25):\n",
        "    if(done == False):\n",
        "      print('Available Actions : ', env.getAvailableActions())\n",
        "      action = agent.ChooseAction(False)\n",
        "      observation, reward, done, _ = env.step(action)\n",
        "      print('Reward: ', reward)\n",
        "      # print('Action: ', action)\n",
        "      # print(\"Visualization Graph\")\n",
        "      # env.render()\n",
        "    else:\n",
        "      print('Goal Reached')\n",
        "      break\n",
        "    print(done)\n",
        "  total_reward_per_episode.append(reward)\n",
        "plt.plot(total_reward_per_episode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fAs_bgJiTOsm",
        "outputId": "cd6ef2a4-abe5-444e-fabc-25ff011f46c8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  1.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  2.0\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Reward:  2.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -2.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -2.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -1.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  4.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  54.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  50\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  1.5\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  2.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  2.5\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  3.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  3.5\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  4.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  4.5\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Reward:  5.0\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.0\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  7.0\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  57.0\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 2]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  1.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  2.0\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  2.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  3.0\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  3.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  4.0\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  4.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  5.0\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  5.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  6.0\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  7.0\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  7.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  8.0\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Reward:  8.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  3.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  4.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  4.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  10.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  60.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -4.0\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  3.0\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  53.0\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56\n",
            "True\n",
            "Goal Reached\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe93d7d4a90>]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent.q_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ca5NvZ8TO3L",
        "outputId": "8cb47a6c-74c4-47ed-977d-166c5b4bc210"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(0, 0): {0: 0, 1: 0.034879523242157, 2: 0, 3: 0.008493203398810309}, (0, 1): {0: 0, 1: 0.0006996700574016584, 2: 0.0040866109624371014, 3: 0.002046908414484544}, (0, 2): {0: 0, 1: 0.18975073789109453, 2: 0.08944599843360407, 3: 0}, (0, 3): {0: 0, 1: 0.13482464616229037, 2: 2.1763264102054682, 3: 0}, (1, 0): {0: 0.0030923235765126116, 1: 0.0029930073596866687, 2: 0, 3: 0.0027443060425107646}, (1, 1): {0: 0.000549878928486891, 1: 0.00024996400188000443, 2: 0.0009493312866177501, 3: 0.001049151434043568}, (1, 2): {0: 0.001900813881089341, 1: 0.012713532822021445, 2: 0.0023998262002970505, 3: 5.023369668950741e-05}, (1, 3): {0: 0, 1: 0.0001999760012799744, 2: 0.0011986829424764634, 3: 0}, (2, 0): {0: 0.007158245704447852, 1: 0.006713809793957964, 2: 0, 3: 0.0005503108230675879}, (2, 1): {0: 0.00015005892290992048, 1: 0.0005499108687814855, 2: 0.0013984790670777774, 3: 0.0009493821616461027}, (2, 2): {0: 0.0010004635269161817, 1: 0.005970506888738051, 2: 0.005030554811998743, 3: 0.0008004413152867659}, (2, 3): {0: 0, 1: -0.010791124587376851, 2: -0.011988606837093933, 3: 0}, (3, 0): {0: 0.012686909246925705, 1: 0, 2: 0, 3: 0.0004997750599895013}, (3, 1): {0: 0.00020025700905259224, 1: 0, 2: 0.006465272783753001, 3: 0.0006505222440662049}, (3, 2): {0: -0.008992982492396322, 1: 0, 2: -0.062123421826182364, 3: -0.006497497686909298}, (3, 3): {0: 0.0007994002799090218, 1: 0, 2: 0.0008493203398810309, 3: 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent.value_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4x9SHs-TPBX",
        "outputId": "7d0c926b-004a-43c3-8550-cd93e332d034"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3.48795232e-02 4.08661096e-03 1.89750738e-01 2.17632641e+00]\n",
            " [3.09232358e-03 1.04915143e-03 1.27135328e-02 1.19868294e-03]\n",
            " [7.15824570e-03 1.39847907e-03 5.97050689e-03 0.00000000e+00]\n",
            " [1.26869092e-02 6.46527278e-03 0.00000000e+00 8.49320340e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper Parameter 1: \n",
        "Gamma Value: 0.3"
      ],
      "metadata": {
        "id": "cAQyCDbFStPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = SARSA_Agent(env, gamma=0.3, epsilon= 0.2, alpha = 0.0001)#0.4,0.8,0.01\n",
        "reward_per_episode = []\n",
        "obs = agent.reset()\n",
        "for j in range(500):\n",
        "  obs = agent.reset()\n",
        "  # x = np.random.randint(0,3)\n",
        "  # y = np.random.randint(0,3)\n",
        "  # env.agent_pos = [x,y]\n",
        "  # while(env.agent_pos[0] == 0 and env.agent_pos[1] == 3):\n",
        "  #   x = np.random.randint(0,3)\n",
        "  #   y = np.random.randint(0,3)\n",
        "  #   env.agent_pos = [x,y]\n",
        "  done = False\n",
        "  action = agent.ChooseAction(True)\n",
        "  cummulative_reward = 0\n",
        "  for i in range(15):\n",
        "    if(done == False):\n",
        "      old_state = env.agent_pos\n",
        "      observation, reward, done, _ = env.step(action)\n",
        "      new_state = env.agent_pos\n",
        "      new_action = agent.ChooseAction(True)\n",
        "      agent.Learn(old_state, action, env.immediate_reward, new_state, new_action)\n",
        "      action = new_action\n",
        "      cummulative_reward = reward\n",
        "      if(done == True):\n",
        "        print('Reward: ', env.immediate_reward)\n",
        "        print('Action: ', action)\n",
        "        print(\"Visualization Graph\")\n",
        "  reward_per_episode.append(cummulative_reward)\n",
        "\n",
        "plt.plot(reward_per_episode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O4MVQyixTPuJ",
        "outputId": "cab79136-4cfc-4b61-ceb9-abfd9e4a906a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe93d6b8f50>]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_reward_per_episode = []\n",
        "for i in range(0,10):\n",
        "  print(\"New Episode!\")\n",
        "  agent.reset()\n",
        "  done = False\n",
        "  for j in range(0,25):\n",
        "    if(done == False):\n",
        "      print('Available Actions : ', env.getAvailableActions())\n",
        "      action = agent.ChooseAction(False)\n",
        "      observation, reward, done, _ = env.step(action)\n",
        "      print('Reward: ', reward)\n",
        "      # print('Action: ', action)\n",
        "      # print(\"Visualization Graph\")\n",
        "      # env.render()\n",
        "    else:\n",
        "      print('Goal Reached')\n",
        "      break\n",
        "    print(done)\n",
        "  total_reward_per_episode.append(reward)\n",
        "plt.plot(total_reward_per_episode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Rro1SB4iTP31",
        "outputId": "33092381-1bcd-4201-9f18-792d01cee6b7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Episode!\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  7.0\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  57.0\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  7.0\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  57.0\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Reward:  1.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -2.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  3.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  53.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 2]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  1.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  2.0\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Reward:  2.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -2.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -2.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -1.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  4.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  54.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -4.0\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  3.0\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  53.0\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  50\n",
            "True\n",
            "Goal Reached\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe93dcfb650>]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV9Z3/8dcnG0sSwpadhH2RJQkQg1aqIhZBQOpOUm07v87ggtZ22jq168z0Z6eOVdtpO620nf5ahai1ggKKWq06VCEmgSysKkJ2CAhJCGT//P7IjaIm5Ca5N+cun+fj4SPJyb25n97Cm5PzPt9zRFUxxhjjf0KcHsAYY0z/WIAbY4yfsgA3xhg/ZQFujDF+ygLcGGP8VNhgvtjYsWN1woQJg/mSxhjj9woKCo6rauwntw9qgE+YMIH8/PzBfEljjPF7InKku+12CMUYY/yUBbgxxvgpC3BjjPFTFuDGGOOnLMCNMcZPuXUWiogcBhqAdqBNVTNF5ElguushI4FTqprhlSmNMcZ8Sl9OI1ykqse7vlDVm7s+F5GHgDpPDmaMMeb8BnweuIgIcBNwxcDH8W2vH6yl4PAHTo8BIqzKSGJybJTTkxhjHORugCvwkogo8Kiqrjvne58FjqrqO909UUTWAGsAUlNTBzKrY1SVn/31HX7+Suf/RBGn54F91fX89ouZzg5ijHGUuwG+UFUrRSQOeFlE9qvqG67vZQO5PT3RFfbrADIzM/3u7hFNre18489FbC2u5vp54/jxdbMZEhbq6Ez/vnkvj+84Qn1TKyOGhjs6izHGOW6dhaKqla6Px4CNQBaAiIQB1wFPemtAJx2tb+KmR9/i+ZJq7ls2g5/emOZ4eAOsSE+kpb2Dl/YcdXoUY4yDeg1wEYkUkeiuz4ElQKnr21cC+1W1wnsjOqOkoo5rfrmd946dZt2tmdx22WTE6WMnLnNTRpI8chhbiqucHsUY4yB39sDjge0iUgTkAVtVdZvre6s5z+ETf/V8STU3PvomYSEhPH3HZ/jczHinR/oYEWFlehLb3znOycYWp8cxxjik12PgqnoISO/he1/29EBOUlV+8eq7PPzyQeaPH8VvbplPbPQQp8fq1oq0RH7z+nts21NDdpZ/lsPGmIGxlZguTa3tfPWJ3Tz88kGum5vM+n9c4LPhDTAraQSTxkayucgOoxgTrCzAgWP1Tdy8bgdbiqu4d+l0HropnaHhzpeV5yMirEhLZMehExxraHJ6HGOMA4I+wEsr61j1q79zsKaB39wynzsvn+IzZWVvVqYn0aHwQkmN06MYYxwQ1AG+rbSaG3/zFgI8fcfFXDUrwemR+mRqfDQzEqLtMIoxQSooA1xV+dXf3uX2xwuZnhDNprsuYVZSjNNj9cuKtETyj5yk6tRZp0cxxgyyoAvwptZ2vv7kbh588QCrMpJ4Ys1FxEUPdXqsfluRlgTA1uJqhycxxgy2oArwYw1NZP92B5t2V/HNJdP42c0ZPl9W9mbC2EjmJMew2Rb1GBN0gibA91bV8/lf/p391Q38+gvzuOuKqX5TVvZmZXoixRV1HDnR6PQog66tvYOX9x6lvqnV6VGMGXRBEeAv7qnhht+8SYfCn2+/mGVzEp0eyaOWuw6jbAnCwyjrd5bxT3/K56Ifv8J3Npawv6be6ZGMGTQBHeCqyq9fe4/bHy9ganw0z911CbOT/bOsPJ/kkcOYP35U0J2Noqrk5pUxLT6K5XMS+UtBBUt/9r/c9Ju32FxURUtbh9MjGuNVARvgzW2dl4F9YNt+VqQl8eSai4gb4b9lZW9WpiWyv6aBd481OD3KoNlVfor9NQ38wyUTefDGdHbct5jvXD2Dmvom7s7dxSUPvMrDLx+kps4WOpnAFJABfvx0Mzm/3ckzhZX88+em8V+r/b+s7M3VcxIRgc1FwXMYZcPOMiIjQlmZ3nkIaVRkBGsuncxr37ycP3z5QuYkx/CLV9/hkgde5c71Bbz53nFU/e6S9Mb0aMC3VPM1+6rr+cc/5nOisZlf5cxjeVpgHe/uSdyIoVw0cQybi6v42pWBU9D2pO5sK1uKq7hu3jiihnz8j3FIiLBoRhyLZsRRduIM63ce4cn8cp4vqWFqXBS3Xjyea+cmE203wzB+LqD2wP+69yg3/PpN2jo6eOq2i4MmvLusSE/kUG0je6sDv8h7dnclTa0d5PRyJcbUMcO57+oL2HHfYh68IY1hEaH84Nk9XPTjV/j+plIOHg2eQ04m8AREgKsqj77+Hv/0WD6T46J4du1C0saNdHqsQbdsdiKhIRLwZ6OoKht2ljEnOcbtUnpoeCg3Zqbw3F0L2bT2Eq6ancCT+eUseeQNVq/rvOtSa7uVnsa/+H2AN7e1862ni/mPF/Zz9exEnlxzMQkxgVtWns/oyAgWThnL5qKqgD7Wu9tVXvb3OugZKSN5+KYMdty3mH9ZOoPyD85y5/pCFj7wKj/760GO1VvpafyDXwf4idPN3PK7nTxdUME9i6fyi+y5DIsI7LKyNyvSEqk4eZaiijqnR/GaDTvLGB4RyjUZSQP6OaMjI7jj8sm8ce8ifv+lTGYkjOBnf32Hz/zkVdZuKGTnoRMB/Q+h8X9+W2IeqGngK398m9qGZn6RPffDMxGC3ZJZCXx3Yymbi6rISAm8w0j1Ta1sLq7i2rnJnyov+ys0RFh8QTyLL4jn8PFGHt9xhKfyy9laXM30+GhuuXg8181NJtJDr2eMp/jlHvir+49y3X//nZa2zrLSwvsjMcPCuXRaLFuLq+noCLy9x2d3dZWX473y8yeMjeR7K2ay8ztX8sD1cwgLFb6/qZQFP36FHz5bGlTn2Rvf59YuhYgcBhqAdqBNVTNd2+8G1rq2b1XVe700J9BZXv1++/vc//w+ZiWN4LdfzCQxZpg3X9IvrUxP5K/7jpJ/5CRZE0c7PY7HqCrrd5YxO3kEc8Z5d0XtsIhQbr4wlZsyUygsO8Vjbx0mN6+cP751hM9MHsMXLx7PlRfEExbql/tAJkD05XfCRap6vOsLEVkErALSVbVZROI8Pt05Wto6+P6mUp7ML2fZ7AQeuimd4RH2K213rrwgnqHhIWwuqgqoAC+qqGN/TQP3Xzt70F5TRJg/fhTzx4/ieyuaefLtcjbsLOP2xwtJjBlKTlYqN2el+PUliY3/Gsjuwx3AT1S1GUBVj3lmpE/7oLGFW36/kyfzy7n7iin8Kmeehfd5RA4JY/GMeF4oraYtgE6N27DzSGd56dAhs7FRQ1i7aAqvf+ty1t06nylxUTz08kEu+cmr3J27i93lpxyZyxcdP91MY3Ob02MEPHcDXIGXRKRARNa4tk0DPisiO0XkdRG5sLsnisgaEckXkfza2tp+Dflvm/ewu/wUP1+dwTeWTCckJLBXGXrCyvREjp9uYcehD5wexSPqm1rZXFTNNelJjq+gDAsNYcmsBB77ygJe+cZl3HLReF47cIzrf/0mb713wtHZfMH7xxtZ9NPXuOeJXU6PEvDcDfCFqjoPWAasFZFL6Tz8Mhq4CPgW8JR0s35bVdepaqaqZsbGxvZryO+vmMlTt13Mqozkfj0/GF0+PY7IiFC2BMiNHp7dXcXZ1nZyFvTv3G9vmRwbxQ9XzmL7v1zBhDHDuWtDIZVBfHu7081trPlTPg1Nbbyy/xgVJ884PVJAcyvAVbXS9fEYsBHIAiqAZ7RTHtABjPXGkGOjhgTkKXHeNDQ8lCWzEnihtMbvL6vatfJyVtII5vjo5YBjhoWz7ouZtLR1cPtjBTS1tjs90qBTVb75VBGHjjfy4A1pADz1drnDUwW2XgNcRCJFJLrrc2AJUApsAha5tk8DIoDjPf0cM/hWpidSd7aV7e/279CVryiuqGNfdT3ZWak+fZGuybFRPHJzBiWVdXx3Y2nQLQL679feY9ueGu5bNoMbM1O4bFosT+aXB1QP42vc2QOPB7aLSBGQR+fpgtuA/wEmiUgp8ATwJQ22P7E+buGUWGKGhbPFzy8xu2FnGcPCQ1k1wJWXg+HKmfF87cqp/KWwgj+9dcTpcQbN3w4c46cvdd4o/CsLJwKQnZXK0fpmXt3vtfMbgl6vp3Ko6iEgvZvtLcAt3hjKeEZEWAhLZyWwtaSaptZ2v7wmekNTK88VVflEeemur14xldLKen60ZS8zEqJZMGmM0yN51eHjjdyTu4sLEkbwk+vSPvwt6YoZccRFDyE3r4wlsxIcnjIw2SqEALciPZHTzW28dsA/D6P4anl5PiEhwsM3p5M6Zjh3ri+kKoBLzcbmNtY8lk9IiPDorfM/di2i8NAQbr4whdcO1gZ1setNFuAB7uJJYxgTGcFmPzwbpau8nJk4gjQvr7z0tBFDw1l3aybNbR3c8XhglpqqyreeLuLdY6f5ZfY8UkYP/9RjbspMAeBJKzO9wgI8wIWFhrBsTgKv7DvqdwsrSirr2FtdT/YC3y4vezIlLoqHb0qnqKKO728KvFLz16+/x/MlNXx72QwWTu3+BLSU0cO5dGosT71tZaY3WIAHgZVpSTS1dvCKn5VJ/lRe9mTJrAS+ungqfy6o4PEdgVNqvnbgGA++eICV6Un802cnnfex2Vmp1NQ38Tc/PYznyyzAg8CFE0YTP2IIm4v85zBKV3m5Mj2REX5SXvbka4unsnhGHP+2eS957/v/ytgjJxr5au4upsdH88D1c3r97WjxBXHEuspM41kW4EEgJERYPieJ1w/UUt/U6vQ4bnmuqIozLe39vuuOLwkJER5ZnUHq6OHcub6A6jr/LfTOtLRx22MFhIQIv/1iplvXJAoPDeHmzBReO3DMykwPswAPEivTE2lp7+ClPUedHsUtuXllXJA4ImBW4I4YGs6jt87nbEs7tz9eSHOb/5WanaVlMQePNvCL7LndlpY9ufnCFBRbmelpFuBBIiNlJONGDfOLwyglFXWUVtaTk5Xil+VlT6bGR/PQTRkUlZ/iB5v2+F2p+egbh9haXM29S2fw2al9u65RyujhfHZqLE/ZykyPsgAPEiLCirQk/v7ucT5obHF6nPPakHeEoeEhrJobeBcvWzo7gbuvmMKT+eWs3+k/x4TfOFjLf27bz/K0RG679PylZU9yslKormvy2zUJvsgCPIisTE+krUPZVlrj9Cg9Ot3cxrO7q1iZluT35WVPvnblNBZNj+XfNu8h/7Dvl5plJ85wd+4upsVH8+ANaf3+rWjxBfFWZnqYBXgQmZk4gkljI336ErPP7XaVl3608rKvQkOEn62eS/LIYdz+eCE1dU1Oj9SjMy2dKy0BHr11/oBupBIeGsJNmeP424FjAb06dTBZgAcREWFFehI7Dp3gWINvhkZuXhkzEqKZGyDlZU+6Lj97pqWNO9YX+GSpqar8y19KOHC0gf/Knsv4MZED/pmrL0ylQ+GpfCszPcECPMisTEukQ+GFEt87jFJSUUdJZR05frrysq+mxUfz0I3p7Co7xb8+t8fpcT7ld//7PpuLqvjWVdO5bFr/bsbySZ1l5liefLuc9g7/KnF9kQV4kJkaH82MhGifPBtlQ15ZZ3kZRHdeWjYnkbWLJpOb13mzZF+x/Z3j/McL+7h6TgJ3XDbZoz87JyuV6romXj/oXyuDfZEFeBBamZ5E/pGTPnUc8nRzG8/trmRFWhIxwwKzvOzJP39uOpdPj+WHz5VScMT5UrP8gzPclVvIlLgoHrwh3eO/DV05M56xUUN86h8sf2UBHoRWpCUCsLXYd270sLmoisYAWXnZV6Ehws9vnkuSq9Q8Wu9cP3G2pZ3bHiugo0NZd2smkUP6X1r2pKvMfHX/Mb9eleoLLMCD0PgxkaSNi/GpS8x2lZfzUgO7vOxJzPDOy882Nrdxx+MFjtzHVFX59jPF7Kup5+fZc5kwduClZU8+LDPfrvDaawQDC/AgtSItkeKKOo6caHR6FEor6yiuqPP5e1562/SEaB68IZ3CslP86+bBLzV/v/19nt1dxTeXTGfR9DivvlbqmK4ys8zKzAGwAA9Sy9M6L9G6xQcOo2zIK2NIWAifD8CVl321PC2ROy6fzIadZYO64OXNd4/zHy/sZ+msBO683LOlZU+ys1KpqmvijYO2MrO/LMCDVPLIYWSOH+X42SiNzW08uys4y8uefHPJdC6dFssPn91DYdlJr79exckzrN1QyKSxkfz0Js+Xlj258oJ4xkZF+NUlBXyNWwEuIodFpEREdotIvmvbv4pIpWvbbhG52rujGk9bkZbI/poG3jna4NgMXeVlzoIUx2bwNaEhwn+tziAhZii3P1bAMS+Wmk2tnaVlW4ey7ouZRHmhtOxJRFgIN8xP4dX9R316Naov68se+CJVzVDVzHO2PeLalqGqz3t6OONdV6clEiKw2cHDKLl5ZUyLj2Je6ijHZvBFI4dH8Oit82loauPO9YVeKTVVlfueKWFvdT0/X53BRC+Wlj3JzkqxlZkDYIdQglhc9FAWTBzDluIqRy5tWlpZR1FFHTlBXl725ILEETx4Yxr5R07y71s8X2r+4e+H2birkn++chpXzIj3+M93x/gxkSycYisz+8vdAFfgJREpEJE152y/S0SKReR/RKTbXSgRWSMi+SKSX1trZYWvWZmexKHaRvZW1w/6a+e6ystr544b9Nf2FyvSkrjtskk8vqOMJ9/23LHit947wf3P72PJzHjWLprisZ/bH9lZqVSeOssb71g+9JW7Ab5QVecBy4C1InIp8GtgMpABVAMPdfdEVV2nqpmqmhkb65nrKRjPWTo7gdAQGfSzURpdl41dnpZIzHArL8/n3qtm8NmpY/n+pj3s8kCpWXnqLGs3FDJxbCQP35xBSIizv/18bmY8YyIjyLUys8/cCnBVrXR9PAZsBLJU9aiqtqtqB/BbIMt7YxpvGR0ZwcIpY9lcNLiHUbYUV3G6uY2cIFx52VehIcIvsucSHzOEOx4vHNCVJJta27n9sQJa2zp49Nb5g1pa9iQiLIQbMsfxyv5jjq5C9Ue9BriIRIpIdNfnwBKgVEQSz3nYtUCpd0Y03rYyPYmKk2fZXX5q0F5zQ145U+OimD/eykt3jBwewaO3ZHLqbAtr+1lqqirf2VhCSWUdj9ycweTYKC9M2j/ZF6bS3qF2z8w+cmcPPB7YLiJFQB6wVVW3Af/pOrWwGFgEfN2LcxovWjIrnojQkEE7jLKnqo6i8lNBc9lYT5mZNIL/vCGdtw+f5P9u3dvn5//xzcM8U1jJ16+cxpUznSktezJhbCSXTBnDE1Zm9kmvAa6qh1Q13fXfLFW937X9VlWdo6ppqnqNqjq/pM/0y4ih4Vw2PZatxdV0DMJfno/KS1t52VfXpCex5tJJ/OmtI3069W7HoRP8aOs+rrwgnruvcLa07ElXmfm/Vma6zU4jNEDnop6a+ibyj3h35d+ZljY27api+ZxERg6P8OprBap7r5rOJVPG8L1NpRS5cdir6tRZ1q4vZPyY4Txyc7rjpWVPlsxM6Cwz7Z6ZbrMAN0Dnsuah4SFeX1q/paia081tAX3PS28LCw3hl9nziIsewm2PFVDb0NzjY5ta27n98QKa2zpYd2sm0T58o+jOlZnj+Os+KzPdZQFuAIgcEsbiC+J5vqSatnbvXcp0Q14ZU+KiyLTyckBGRXau1Dx1toW1Gwpp7eb/M1Xle5tKKa7oLC2nxPlOadmT1VmdZeafbWWmWyzAzYdWpiVyorGFHYe8c1eYvVX17C4/ZSsvPWRWUgwPXJ9G3vsfcP/WfZ/6/mM7jvB0QQX3LJ7K53ystOzJxLGRfGbyGHLzygelj/F3FuDmQ5dPjyNqSJjXDqPk5pURERbCdfOsvPSUVRnJ/OPCify/Nw/zdMFHN0fIe/8D/n3zXhbPiOOexVMdnLDvPiwz3z3u9Cg+zwLcfGhoeCifmxnPtj01Hr94Umd5WWnlpRd8e9kMPjN5DN/ZWEJxxSmq685y5/oCUkcP55HVzq+07Ksls+IZbSsz3WIBbj5mZXoidWdb2f6uZ0/l2lJcTUNzW1De89LbwkJD+GXOPGKjOkvN2x4r4GxLO+u+OJ8RPlxa9mRIWCg3zB/Hy/uOevVSuoHAAtx8zMIpscQMC2dzkWdP6891lZcXTrDy0htGu0rNDxpbKK6o46GbMpgSF+30WP22+sKUzjKzwO6ZeT4W4OZjIsJCWDorgZf3HqWptd0jP3NfdT27yk4F/T0vvW12cgx/+PKF/Hx1BktnJzg9zoBMio3i4kljyM0rszLzPCzAzaesTE/idHMbrx045pGf92F5aSsvve4zU8ayKiMw3ufsBalUnDzLdisze2QBbj7lokmjGRMZ4ZE79ZxtaWdjYSVXz05gVKSVl8Z9V82KZ9TwcFuZeR4W4OZTwkJDuHpOIq/sO0pjc9uAftaW4iorL02/fFhm7j06oEvoBjILcNOtlelJNLV28Mr+gR1Gyc0rY1JsJFkTR3toMhNMsrNSaetQ/pxvZWZ3LMBNtzLHjyJhxNABLerZX1NPYZmtvDT9Nyk2iosmjeaJt63M7I4FuOlWSIiwPC2R1w/UUne2tV8/I3dnGRGhIVw/z+55afovOyuV8g/O8vf3rMz8JAtw06MVaYm0tHfw8t6jfX7u2ZZ2ntlVybI5Vl6agblqVoKVmT2wADc9ykgZybhRw/p1GGVrSTUNTVZemoEbGh7K9fPG8dKeo+e9dG4wsgA3PRIRVqQl8fd3j/NBY0ufnpubV8aksZEssPLSeMDqrjKzwC4zey4LcHNeK9MTaetQtpXWuP2cAzUNFBw5aSsvjcdMiYtiwcTRPGGXmf0YtwJcRA67bmC8W0TyP/G9b4iIishY74xonDQzcQSTYiP7dBglN89VXs638tJ4Ts6CVMo+OMOb751wehSf0Zc98EWqmqGqmV0bRCQFWAJYuxCgug6j7Hj/hFtXhjvb0s4zhRUsnZ3AaCsvjQddNSuBkVZmfsxAD6E8AtwL2O80AWxlWiKq8HxJ70vrny+ppt7KS+MFXWXmi3tqrMx0cTfAFXhJRApEZA2AiKwCKlW16HxPFJE1IpIvIvm1tZ69xrQZHFPjo5mREM0WN66NkptXxsSxkVw0ycpL43nZWSm0dSh/KbSVmeB+gC9U1XnAMmCtiFwKfAf4QW9PVNV1qpqpqpmxsbEDGNU4aWV6EvlHTlJ16myPjzl4tIH8IyfJzkqx8tJ4xZS4aLImjrbLzLq4FeCqWun6eAzYCFwGTASKROQwMA4oFBH/vgix6dGKtEQAtp5nL3yDa+XlDfNTBmssE4RyslI5cuIMbx2yMrPXABeRSBGJ7vqcztLybVWNU9UJqjoBqADmqar755oZvzJ+TCRp42LYXNz92ShNrZ3l5VVWXhovWzo7gZhh4WywMtOtPfB4YLuIFAF5wFZV3ebdsYwvWpmWRHFFHYePN37qex+Vl7b3bbzro5WZNRw/HdxlZq8BrqqHVDXd9d8sVb2/m8dMUFW70kyAW951GKWbs1Fy88qYMGY4F08aM9hjmSCUsyCF1nblL0F+z0xbiWncljRyGJnjR31qUc87Rxt4+7CtvDSDZ0pcNFkTrMy0ADd9sjI9if01DbxztOHDbRvyyggPFVt5aQZV9oIUDp84w44gLjMtwE2fLJuTQIjw4f0yO8vLSq6alcDYqCEOT2eCybLZiUFfZlqAmz6Jix7KRZPGsKWoClXlhdJq6s62kmMrL80gGxoeynXzknlxTw0ngrTMtAA3fbYiLYlDxxvZW11P7s5yJowZzkVWXhoH5GSldpaZQboy0wLc9NnS2QmEhQiPvPwOeYc/YHVWKiEhVl6awTc1PpoLJ4wiN68c1eArMy3ATZ+Njoxg4dSx/HXfUcJDhRusvDQOys5K5f3jjUG5MtMC3PTLirQkAJZYeWkcdvWcREYMDSM3L/ju1mMBbvpl6ewELp8eyx2XTXZ6FBPkOsvMcbxYGnxlpgW46ZeoIWH8v3/IYnZyjNOjGEN2Viot7R08U1jp9CiDygLcGOP3pidEM3/8KHLzyoKqzLQAN8YEhJysVA4db2THoQ+cHmXQWIAbYwLC8rSuMjN4VmZagBtjAkJXmbmttIYPGlucHmdQWIAbYwLG6qwUV5kZHCszLcCNMQFjRsII5qWOZEOQlJkW4MaYgJKzYDyHahvZ+X7gl5kW4MaYgLJ8TiLRQVJmWoAbYwLKsIhQrpubzAslNZwM8DLTrQAXkcMiUiIiu0Uk37XtRyJS7Nr2kogkeXdUY4xxT/aCzpWZgX6Z2b7sgS9S1QxVzXR9/aCqpqlqBrAF+IHnxzPGmL6bkTCCuakjA35lZr8Poahq/TlfRgKB+y4ZY/xOTlYq79U2khfAZaa7Aa7ASyJSICJrujaKyP0iUg58gR72wEVkjYjki0h+bW3twCc2xhg3rEhLCvgy090AX6iq84BlwFoRuRRAVb+rqinAeuCu7p6oqutUNVNVM2NjYz0ytDHG9GZYRCjXzk3m+dLALTPdCnBVrXR9PAZsBLI+8ZD1wPWeHc0YYwZm9YWptLR18MyuwLzMbK8BLiKRIhLd9TmwBCgVkannPGwVsN87IxpjTP/MTBpBRkrglpnu7IHHA9tFpAjIA7aq6jbgJyJSKiLFdIb6PV6c0xhj+iVnQSrvHjtN/pGTTo/icWG9PUBVDwHp3Wy3QybGGJ+3Ii2RH23ey4adZVw4YbTT43iUrcQ0xgS04RFhfH5uMltLqjl1JrDKTAtwY0zAy85ylZkBds9MC3BjTMCbmTSC9AAsMy3AjTFB4QtZqbxz7DQFAVRmWoAbY4LCivREooaEsWFn4KzMtAA3xgSFzjIziS0BVGZagBtjgkZXmbkxQFZmWoAbY4LGrKQY0sfFBEyZaQFujAkqOQtSOXj0NIVl/l9mWoAbY4LKirQkooaEsT4AykwLcGNMUIkcEsaqjCS2FldTd6bV6XEGxALcGBN0srNSaW7rYOMu/75npgW4MSbozE6OIW1cDLl55X5dZlqAG2OCUk5WKgeONlBYdsrpUfrNAtwYE5RWpicRGRHq1yszLcCNMUEpckgYq+Yms6W4ym/LTAtwY0zQynGVmZt2++fKTAtwY0zQmp0cw5xk/12ZaQFujAlqOQtS2V/TwK5y/ysz3amYn4gAAAmWSURBVApwETksIiUisltE8l3bHhSR/SJSLCIbRWSkd0c1xhjP8+cysy974ItUNUNVM11fvwzMVtU04CBwn8enM8YYL4saEsY1Ga4y86x/lZn9PoSiqi+papvryx3AOM+MZIwxgysnK5Wm1g6e9bMy090AV+AlESkQkTXdfP//AC9090QRWSMi+SKSX1tb2985jTHGa+aMi2F28gg27PSvMtPdAF+oqvOAZcBaEbm06xsi8l2gDVjf3RNVdZ2qZqpqZmxs7IAHNsYYb8jO6iwzd/tRmelWgKtqpevjMWAjkAUgIl8GVgBfUH/6Z8sYYz5hVUYyw/2szOw1wEUkUkSiuz4HlgClIrIUuBe4RlXPeHdMY4zxrijXZWY3F1dR3+QfZaY7e+DxwHYRKQLygK2qug34JRANvOw6vfA3XpzTGGO8LrurzPSTe2aG9fYAVT0EpHezfYpXJjLGGIfMSY5hVtII1u8s45aLxiMiTo90XrYS0xhjXETkwzKzqKLO6XF6ZQFujDHnWJWR5Cozjzg9Sq8swI0x5hzRQ8O5Jj2JzUXVPl9mWoAbY8wnZGelcra1nWd3Vzk9ynlZgBtjzCekjYthZqLvr8y0ADfGmE8QEbIXpLKvup5iHy4zLcCNMaYbn89IYli4b6/MtAA3xphudJWZzxVV0eCjZaYFuDHG9CB7gW+XmRbgxhjTg/RxMVzgw2WmBbgxxvRARMjJSmFvdT0llb5XZlqAG2PMeayam+yzZaYFuDHGnMeIoeGsTE/0yTLTAtwYY3qRnZXKmZZ2nivyrTLTAtwYY3qRkTKSGQnR5Ob51mEUC3BjjOmFiJCzIJXSynpKfGhlpgW4Mca44fNzkxkaHsIGH9oLtwA3xhg3jBgazsq0JJ7bXcnp5janxwEswI0xxm3ZC1JpbGnnOR9ZmWkBbowxbprrY2WmWwEuIodFpMR19/l817YbRWSPiHSISKZ3xzTGGOd13TOzpLLOJ8rMvuyBL1LVDFXtCutS4DrgDc+PZYwxvqmrzMx92/m98H4fQlHVfap6wJPDGGOMr4sZFs6KtCSe3eV8melugCvwkogUiMiavryAiKwRkXwRya+tre37hMYY42OyszrLzM0Or8x0N8AXquo8YBmwVkQudfcFVHWdqmaqamZsbGy/hjTGGF8yL3Uk0+OdLzPdCnBVrXR9PAZsBLK8OZQxxviyzjIzheKKOkodvMxsrwEuIpEiEt31ObCEzgLTGGOC1rXzxjEkLMTRvXB39sDjge0iUgTkAVtVdZuIXCsiFcDFwFYRedGbgxpjjC/5sMzcXUWjQ2VmrwGuqodUNd313yxVvd+1faOqjlPVIaoar6pXeX9cY4zxHTkLUjjd3OZYmWkrMY0xpp/mpY5iWnyUY4dRLMCNMaafulZmFjlUZlqAG2PMAFw3t7PMfMKBlZkW4MYYMwAxw8NZnpbIpl2DX2ZagBtjzADlZKVyurmNLcWDW2ZagBtjzADNHz+KqXFRbMgrH9TXtQA3xpgB+rDMLD/FnqrBKzMtwI0xxgOum5fcWWYO4l64BbgxxnjAyOERLJ+TyKZdlZxpGZwy0wLcGGM8JHtBKg3NbWwpqh6U17MAN8YYD8kcP4opcVFsGKSVmRbgxhjjIV1l5u7yU+ytqvf661mAG2OMB10/L5mIQVqZaQFujDEe1FVmbiz0fplpAW6MMR6WneUqM4u9W2ZagBtjjIddOGEUk2MjvX6ZWQtwY4zxsK4yc1fZKfZVe6/MtAA3xhgvuH7euM4y04t74RbgxhjjBaMiI7h6dgLP7KrkbEu7V17DrQAXkcMiUiIiu0Uk37VttIi8LCLvuD6O8sqExhjjp7KzUmlo8t5lZvuyB75IVTNUNdP19beBV1R1KvCK62tjjDEuWRNHM8mLZeZADqGsAv7o+vyPwOcHPo4xxgQOESEnK5XCslPsr/F8melugCvwkogUiMga17Z4Ve06ybEGiO/uiSKyRkTyRSS/trZ2gOMaY4x/uW7eOC6dFktrm3r8Z4tq7z9URJJVtVJE4oCXgbuB51R15DmPOamq5z0OnpmZqfn5+QOd2RhjgoqIFJxz+PpDbu2Bq2ql6+MxYCOQBRwVkUTXD08EjnluXGOMMb3pNcBFJFJEors+B5YApcBzwJdcD/sS8Ky3hjTGGPNpYW48Jh7YKCJdj9+gqttE5G3gKRH5CnAEuMl7YxpjjPmkXgNcVQ8B6d1sPwEs9sZQxhhjemcrMY0xxk9ZgBtjjJ+yADfGGD9lAW6MMX7KrYU8HnsxkVo6z1jpj7HAcQ+O4+/s/fiIvRcfZ+/HxwXC+zFeVWM/uXFQA3wgRCS/u5VIwcrej4/Ye/Fx9n58XCC/H3YIxRhj/JQFuDHG+Cl/CvB1Tg/gY+z9+Ii9Fx9n78fHBez74TfHwI0xxnycP+2BG2OMOYcFuDHG+Cm/CHARWSoiB0TkXREJ2ntvikiKiPxNRPaKyB4RucfpmXyBiISKyC4R2eL0LE4TkZEi8rSI7BeRfSJysdMzOUVEvu76e1IqIrkiMtTpmTzN5wNcREKBXwHLgJlAtojMdHYqx7QB31DVmcBFwNogfi/OdQ+wz+khfMTPgW2qOoPOq4gG5fsiIsnAV4FMVZ0NhAKrnZ3K83w+wOm8+8+7qnpIVVuAJ+i8oXLQUdVqVS10fd5A51/OZGencpaIjAOWA79zehaniUgMcCnwewBVbVHVU85O5agwYJiIhAHDgSqH5/E4fwjwZKD8nK8rCPLQAhCRCcBcYKezkzjuZ8C9QIfTg/iAiUAt8AfXIaXfue6iFXRct4H8KVAGVAN1qvqSs1N5nj8EuPkEEYkC/gJ8TVXrnZ7HKSKyAjimqgVOz+IjwoB5wK9VdS7QCARlZyQio+j8TX0ikAREisgtzk7lef4Q4JVAyjlfj3NtC0oiEk5neK9X1WecnsdhlwDXiMhhOg+tXSEijzs7kqMqgApV7fqt7Gk6Az0YXQm8r6q1qtoKPAN8xuGZPM4fAvxtYKqITBSRCDqLiOccnskR0nlj0t8D+1T1YafncZqq3qeq41R1Ap1/Ll5V1YDby3KXqtYA5SIy3bVpMbDXwZGcVAZcJCLDXX9vFhOAha47NzV2lKq2ichdwIt0Nsn/o6p7HB7LKZcAtwIlIrLbte07qvq8gzMZ33I3sN61s3MI+AeH53GEqu4UkaeBQjrP3tpFAC6pt6X0xhjjp/zhEIoxxphuWIAbY4yfsgA3xhg/ZQFujDF+ygLcGGP8lAW4Mcb4KQtwY4zxU/8fIsvlcCtDyZsAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent.q_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtzxdV2JTQDQ",
        "outputId": "d0ab0e96-8a69-40cb-ec76-93b9bf21df53"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(0, 0): {0: 0, 1: 0.029414612317687102, 2: 0, 3: 0.00599670109975254}, (0, 1): {0: 0, 1: 0.0009497085596320289, 2: 0.002893981371821428, 3: 0.0012997064087570537}, (0, 2): {0: 0, 1: 0.18935159188241893, 2: 0.07823234916130642, 3: 0}, (0, 3): {0: 0, 1: 0.09491454843062581, 2: 2.1524073981853697, 3: 0}, (1, 0): {0: 0.003540923300137849, 1: 0.0027450851170744833, 2: 0, 3: 0.0032443085791310643}, (1, 1): {0: 0.0005998259965586161, 1: 0.000549849502785114, 2: 0.000549873478526448, 3: 0.0009993202989294608}, (1, 2): {0: 0.0015035857456524898, 1: 0.014491372508803961, 2: 0.00015064093104310842, 3: 0.00010073202935003466}, (1, 3): {0: 0, 1: 9.99965e-05, 2: 0.001098878744267187, 3: 0}, (2, 0): {0: 0.00879420133998317, 1: 0.0076615728372733585, 2: 0, 3: 0.0007006015740804833}, (2, 1): {0: 0.0008994572119474486, 1: 0.0006997475171668911, 2: 0.0010992278009743298, 3: 0.0006498379387291517}, (2, 2): {0: 0.0006515310548907109, 1: 0.010910420772936191, 2: 0.002303678308830551, 3: 0.0016020264282601423}, (2, 3): {0: -0.0017998200060000001, 1: -0.008993738684207091, 2: -0.013186508743128121, 3: 0}, (3, 0): {0: 0.016037962698221372, 1: 0, 2: 0, 3: 0.0012485011493677655}, (3, 1): {0: 0.002746920917820472, 1: 0, 2: 0.009680692041525205, 3: 0.0011008641281327893}, (3, 2): {0: -0.013488036723683112, 1: 0, 2: -0.11421250737057745, 3: -0.0039986602529701026}, (3, 3): {0: 0.00024995000499975, 1: 0, 2: 0.0009491454843062581, 3: 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent.value_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1nTR8GpTQOQ",
        "outputId": "adecb100-45a2-4254-a7fe-4e09097b6aac"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.94146123e-02 2.89398137e-03 1.89351592e-01 2.15240740e+00]\n",
            " [3.54092330e-03 9.99320299e-04 1.44913725e-02 1.09887874e-03]\n",
            " [8.79420134e-03 1.09922780e-03 1.09104208e-02 0.00000000e+00]\n",
            " [1.60379627e-02 9.68069204e-03 0.00000000e+00 9.49145484e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper Parameter 1: \n",
        "Gamma Value: 0.4"
      ],
      "metadata": {
        "id": "NJKRn7s0SvEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = SARSA_Agent(env, gamma=0.4, epsilon= 0.2, alpha = 0.0001)#0.4,0.8,0.01\n",
        "reward_per_episode = []\n",
        "obs = agent.reset()\n",
        "for j in range(500):\n",
        "  obs = agent.reset()\n",
        "  # x = np.random.randint(0,3)\n",
        "  # y = np.random.randint(0,3)\n",
        "  # env.agent_pos = [x,y]\n",
        "  # while(env.agent_pos[0] == 0 and env.agent_pos[1] == 3):\n",
        "  #   x = np.random.randint(0,3)\n",
        "  #   y = np.random.randint(0,3)\n",
        "  #   env.agent_pos = [x,y]\n",
        "  done = False\n",
        "  action = agent.ChooseAction(True)\n",
        "  cummulative_reward = 0\n",
        "  for i in range(15):\n",
        "    if(done == False):\n",
        "      old_state = env.agent_pos\n",
        "      observation, reward, done, _ = env.step(action)\n",
        "      new_state = env.agent_pos\n",
        "      new_action = agent.ChooseAction(True)\n",
        "      agent.Learn(old_state, action, env.immediate_reward, new_state, new_action)\n",
        "      action = new_action\n",
        "      cummulative_reward = reward\n",
        "      if(done == True):\n",
        "        print('Reward: ', env.immediate_reward)\n",
        "        print('Action: ', action)\n",
        "        print(\"Visualization Graph\")\n",
        "  reward_per_episode.append(cummulative_reward)\n",
        "\n",
        "plt.plot(reward_per_episode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tH2g3FzfTREM",
        "outputId": "780d1a8a-9c7b-454a-aca4-7d5bc3abb7f3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe93d788b10>]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_reward_per_episode = []\n",
        "for i in range(0,10):\n",
        "  print(\"New Episode!\")\n",
        "  agent.reset()\n",
        "  done = False\n",
        "  for j in range(0,25):\n",
        "    if(done == False):\n",
        "      print('Available Actions : ', env.getAvailableActions())\n",
        "      action = agent.ChooseAction(False)\n",
        "      observation, reward, done, _ = env.step(action)\n",
        "      print('Reward: ', reward)\n",
        "      # print('Action: ', action)\n",
        "      # print(\"Visualization Graph\")\n",
        "      # env.render()\n",
        "    else:\n",
        "      print('Goal Reached')\n",
        "      break\n",
        "    print(done)\n",
        "  total_reward_per_episode.append(reward)\n",
        "plt.plot(total_reward_per_episode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0fkRMem0TRMb",
        "outputId": "0b9771ac-7558-4237-d96c-c9959f977c32"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  7.0\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  57.0\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  7.0\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  57.0\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  7.0\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  57.0\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  1.5\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  2.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  2.5\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  3.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  3.5\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  4.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  4.5\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  5.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  5.5\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  6.5\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  7.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  7.5\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Reward:  8.0\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  3.0\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  3.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  4.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  10.0\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  60.0\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 2]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  1.5\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Reward:  2.0\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.0\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -2.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -2.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  4.0\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  54.0\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56\n",
            "True\n",
            "Goal Reached\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe93d9d86d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent.q_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qAXPc7uTRW_",
        "outputId": "89cabb15-7392-4a71-8c08-afb34e083df3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(0, 0): {0: 0, 1: 0.020459053249402455, 2: 0, 3: 0.0049977505998950135}, (0, 1): {0: 0, 1: 0.0004002415502893873, 2: 0.00224689687720395, 3: 0.0019484079431253882}, (0, 2): {0: 0, 1: 0.20512273257498545, 2: 0.073501742523337, 3: 0}, (0, 3): {0: 0, 1: 0.05497250824835023, 2: 2.1763264102054682, 3: 0}, (1, 0): {0: 0.002496098885134865, 1: 0.002296879534614111, 2: 0, 3: 0.004287401495432219}, (1, 1): {0: 0.0005999578689259781, 1: 0.0002501258793708359, 2: 0.00114931518675603, 3: 0.0011991244256852156}, (1, 2): {0: 0.0016059897996544338, 1: 0.015052544425794318, 2: 0.0011033950802114686, 3: 5.001399700036078e-05}, (1, 3): {0: 0, 1: 5e-05, 2: 0.0006496201409644563, 3: 0}, (2, 0): {0: 0.00825716943450181, 1: 0.007664183799390684, 2: 0, 3: 0.0014992679365453826}, (2, 1): {0: 0.0006500616657982017, 1: 0.0010496457565794908, 2: 0.0018479574410171027, 3: 0.000999733666373096}, (2, 2): {0: 0.0008512616227711915, 1: 0.008256849124460766, 2: 0.005039562648643903, 3: 0.0012520863621276188}, (2, 3): {0: -0.00119994, 1: -0.0059973247078764155, 2: -0.011988774603008859, 3: 0}, (3, 0): {0: 0.016376634509241757, 1: 0, 2: 0, 3: 0.0004997750599895013}, (3, 1): {0: 0.0005510298135176409, 1: 0, 2: 0.008947817316707721, 3: 0.0008514656981372639}, (3, 2): {0: -0.00949171445454417, 1: 0, 2: -0.08775389575305657, 3: -0.005996741061768736}, (3, 3): {0: 0.00029992500999925, 1: 0, 2: 0.0008992354078470428, 3: 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent.value_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WnGgH3HTRgw",
        "outputId": "2190e2bb-5023-4261-a0d2-edb5755ebc10"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.04590532e-02 2.24689688e-03 2.05122733e-01 2.17632641e+00]\n",
            " [4.28740150e-03 1.19912443e-03 1.50525444e-02 6.49620141e-04]\n",
            " [8.25716943e-03 1.84795744e-03 8.25684912e-03 0.00000000e+00]\n",
            " [1.63766345e-02 8.94781732e-03 0.00000000e+00 8.99235408e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper Parameter 2: \n",
        "Epsilon Value: 0.1"
      ],
      "metadata": {
        "id": "TUGE-za1Sycb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = SARSA_Agent(env, gamma=0.1, epsilon= 0.1, alpha = 0.0001)#0.4,0.8,0.01\n",
        "reward_per_episode = []\n",
        "obs = agent.reset()\n",
        "for j in range(500):\n",
        "  obs = agent.reset()\n",
        "  # x = np.random.randint(0,3)\n",
        "  # y = np.random.randint(0,3)\n",
        "  # env.agent_pos = [x,y]\n",
        "  # while(env.agent_pos[0] == 0 and env.agent_pos[1] == 3):\n",
        "  #   x = np.random.randint(0,3)\n",
        "  #   y = np.random.randint(0,3)\n",
        "  #   env.agent_pos = [x,y]\n",
        "  done = False\n",
        "  action = agent.ChooseAction(True)\n",
        "  cummulative_reward = 0\n",
        "  for i in range(15):\n",
        "    if(done == False):\n",
        "      old_state = env.agent_pos\n",
        "      observation, reward, done, _ = env.step(action)\n",
        "      new_state = env.agent_pos\n",
        "      new_action = agent.ChooseAction(True)\n",
        "      agent.Learn(old_state, action, env.immediate_reward, new_state, new_action)\n",
        "      action = new_action\n",
        "      cummulative_reward = reward\n",
        "      if(done == True):\n",
        "        print('Reward: ', env.immediate_reward)\n",
        "        print('Action: ', action)\n",
        "        print(\"Visualization Graph\")\n",
        "  reward_per_episode.append(cummulative_reward)\n",
        "\n",
        "plt.plot(reward_per_episode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2TqbWezlTSRv",
        "outputId": "f65a0947-ec0c-4844-b1ec-95a83557bfaa"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe93d7edd90>]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2deZwUxdnHfzUze7C73Cy3yKlyKKAIeEvUeIuvMR4xhuTV+L5vLqN5k2hOj7wGY6LBxBiJmhhjjFeiiUm8EG9FQREVQRA5BXZBFnYX9piZev/orp7q6upzume6Z+v7+cBOd1dXV3dXP/XUU089RSilUCgUCkXySJW7AAqFQqEIhhLgCoVCkVCUAFcoFIqEogS4QqFQJBQlwBUKhSKhZEp5sUGDBtHRo0eX8pIKhUKReJYtW7aDUtoo7i+pAB89ejSWLl1ayksqFApF4iGEbJDtVyYUhUKhSChKgCsUCkVCUQJcoVAoEooS4AqFQpFQlABXKBSKhKIEuEKhUCQUJcAVCoUioSgBrlCUiI92tOPltTvKXQxFBVHSiTwKRU9mzs+fAwCsn396eQuiqBiUBq5QKBQJRQlwhUKhSChKgCsUCkVCUQJcoVAoEoonAU4IuYIQ8h4h5F1CyP2EkFpCyBhCyBJCyFpCyAOEkOqoC6tQKBSKAq4CnBAyAsA3AMyglE4BkAZwAYAbAdxCKR0PYBeAS6IsqEKhUCjMeDWhZAD0IoRkANQB2ArgUwAe1o/fA+Ds8IunUCgUCjtcBTildAuAnwPYCE1w7wawDEALpTSrJ9sMYITsfELIZYSQpYSQpc3NzeGUWqFQKBSeTCj9AcwFMAbAcAD1AE7xegFK6UJK6QxK6YzGRsuKQLFj975udHTnyl0MhUIRYyilaNrTUe5ieDKhnAjgI0ppM6W0G8BfARwFoJ9uUgGAkQC2RFTG0Gjt6EYuTx3TTL32KZz5q5dKVCKFIji793Uj71KfFdHw6PItmHnDIizf1FLWcngR4BsBzCaE1BFCCIATAKwEsBjAuXqaeQAei6aI4dCdy+Pga57CDx9717Q/l6cWjXtNU1spi6ZQ+OaT9i5MvfYpLFi0ptxFKQkd3Tlkc/lyF8Pg3S17AACvf7SzrOXwYgNfAm2w8k0A7+jnLATwXQBXEkLWAhgI4K4Iy1k0nVnt5T/2lrmj8K0Hl+OgHz5RjiIpeiiUFq8172zrBAD8652tReeVBA764RP48h/jsyD64N41AIDtezrLWg5PwawopT8G8GNh9zoAM0MvUUQw00mKENP+R5d/XI7iKHoweQqkiXs6J1g17kkGlMWr4+ME0a+uCgDQ1FpeAd5jZmIyrYcU+eEoFMWSD0EDB7SKHIY2r/APG3rYXuaBzB4jwNkDT6WUBFeUF7eBdC8E1cC7snk18BkCzB6/Q2ngpYF9NGmlgivKTJhKs5+8PtjeigN+8G9cfPeS8ArQQ8nq8qTcLsc9RoDnDROKEuCK8hKGCYVp0X5MKFta9gEAXl5bXs+JSiCb0557V668vZkeI8CzxiCmfRrVtVSUgjAEeE7Pw09OSa3fcbTzd+c1E0p3mV0be4wAz9t4ofBkE1rBFcki7/LNn3/Hq7juHysd0zAN0E9jEIbtvRzEsdg5/fkrAV4imHBOO6jgSa3gimThJnSXfPQJ7n75I095sKwWvb8ds254xtEmm9TqHcfvslsvU1dWCfCSwCqBnQJOKUXWTTVyYEdbJ869/RVs213++AiKeHPsTYvR3pm17F/wzBpc8cByT3nk8mYBfu0/VmL7nk7H+heO+2LpiWO5mRdKNk/LqoX3GAHOKoGdCYXSQrc0CKu2tmLphl1YtW1P4DwUPYPWjize3bLbsv+WZz7A397yFlJI1EpZ/X5o2SZ87c9vejonKcSx3HyZvnLfm/jTaxssaXbv68Ypv3wBa7a3RlaOHiPAmXC2s6BQFGcDb9M1qmIaAUX8eGnNDnzVRiAWQ7HjLTnBC4Upqbct/hCPr5BPr4+jJuuFOI5NdXPf+dMrt+MHj75rSfPc6ias2taKW59dG1k5eowAd9fA/ZtQfvqv941YFKxLHMfKpgjOF+5egn+u2Iq9XVaTRzGEJcBZNl6Ec1IFeBy9Z3JFmFvDpMcIcMON0EYFp/CvPd/xwjp85T5NO2MfeDF2dEX86FenLfW6s60r1HyLFQAFN0Lv3igxCubni1wMG57umDQqPUaA51z8wCktztbW1qmN/isTSmXRr5cWtGhne3ECXNQiu4usJ+IgppeqG0dN1gtxtIHHJbRtDxTgdhp4cV4oTAMvt19oqXl57Q7c++r6chcjMljUuU/ai4t5IWqRxQol0YTiZbILX4Y4To6xI5YCPCZl6nEC3G4qPaXhDGLGsbJFyUV3LsEPH3uv3MWIDGZC2VGkCUWsF8U29IX8zIKcIdO2+TIkqZrG8ZuS9bTX72jHL5/5oKSNY+IFeNOeDix4Zo3rQysMYtqnKcb8wQYx42IbU4SDYUJp68Jti9di8669gfIRhVBYGnjBhGLOT6aM8N9IksZqYinAJc/vP//wBn75zBpsLeFckMQL8CsffBu3PPMB3t5s9avlcZuJWawG3t7FbODJ+TAU7lRntE9kxeYW3PTkalx6T7BVYcS6VbQXihALRRRyMgHDp4mjULQjjoOY2RxFQ415PZx9+ixYsbRRhs9LvABv7zKbLiiluOulj7BLGHTKu5lQQIvyDGhXfuAVCatXTKvava/bMX17Zxa/ff5DV407LBOK6AfOkDUQfNWMiw3Xib++uRnrmttiOfiazVPU16TLXYzkC3CRtzfvxvWPr8S3H37btN9LNEI/wlc02Sg/8MqECcr1O9sBuHuP3PTkasz/9yrLWpWiRlxsDA23QUxZXeYFYS4BisaVD76NUxe8GLoG/re3NhuhdYOSzVP0qpILcPZsS9FxqDgBzj4MUVNy9ULxaUIRk7Z3KhNKJcLqRMvebn278H6XrNuJdwTTHRvM3tdlDiolauCdIQlwJrhFISerh3mTDTz+AhzQnlOYvdqubB5XPPA2Llj4alH5ZHN59KqWLyncpT/7UpipEi/AxVbObjDTbUUeCn+VWnw5zJSjBjHjx4rNLdLYI16wCsbC9vkLX8OZv34JL64pLLbL6pdlUFEQQp3dIQlwfVusdnITSnJs4HxvIcwZpMx0Vexq8tkcRa8qs/hkkuX+1zeiO5dXAtwPbgvtsMrrGI3Qh/ZsEeA9XAOPo52ScdavX8YZv3op0LmiqUFmu774rteN3yn9ixIfh1hfunLFLcWVE2zffk0ocfdC4RugMAUhe3/FDixm83n0qpabUO566SN84a7Xsa0ECx7L+wAVABFekduCDr41cBsbeNw1GydaO7rx5sYWHHdAo+9zc5QiFel4e3kQ37Pb4COx0cDFfIrVwMUl1awauMwLhT+/qMtHTlQeM2HF787mKarS9vrvq+t24tV12tJ1Ua7iWDEauJsfeCEWira9bMMufMJ5qvidSs9rZrk8NVyIip0iXU6+ct+bmHf369jZZu5evrVxF5pdVt+uVO8ba9hW7a9dfWOD5OJxqwZenCDJWkwo7m6KOZokDbxQvlAFONPAixSq3TmKTKr84rNiNHBRgFDBG1PUwD9z+ysY0a8Xf4Iv1y6+gvGR6uL+YTjx9qYWAGZtjlKK//jNKxg7qB7P/u/xtudq911+t6qwsRMe4iBkLk+RThGj52fRiKOygRsNivm4rC7TBNnA+ecVphcKU7DEHrpfcvk8MoJLWzkWTC9/ExIS4qCOSFZiQuFdiTQ/8GAmFGb/BpKtgbPJSPxz2LNPa5zW7Wh3PLeSNXDxQwW0RRl4WNecJbWYUCxeKMXZwI0l1WxqvKwu8/vszIUft+wLPNs0TPjyedGJ3t+6B60dzj76QOE9FStrszmKTLr8JsOKEeDshdsNpjGB6xSNMKgXShu3PFZc4gQHgd0T34toatUGYqod7H3aOZUrwGsy1ntv65QLcKaF8fK7ozuHdz82e8GEZUKxe+wyRcKLF8qR85/F0TcuLqpsYWBubJyfFaUUpy54EV/6/Ruu+YY3iOlsAy8VFWNCKQgfeRcpl2MaUjjxwPkKZjKhVIAmyt8bc7fq08u5qiTZdORELk9RW5U2eicMcU3LLS370JnLGfWL18B/8Oi7eHjZZlN60YQiUzwopbbdciO9TXWTCei8Bw08LvD1yc2NkJmzlm7Y5ZpvwQZenAjP5vKOC6TzRPmoy9+EFMFHXLeeVUjLYFE2j8279hrTiO2jEfqbSm+ngcv8wDfsbI/Uza5lbxd2tXeBUmp6JkHhtTemgfeurXI8p2lPJ3bvde/CAsDOtk7XKelxIUflGrhoQjnt1hcx8/8WcYOYhWOvf/SJ5XzRhi4TqE5CtjCIKU8jn8hT+B1mT3Hb7o7QVyz6sLlQj906Kx3d3s1RRk8pUKkKdOcpqjyaUKLslSdSgGdzeTyybDPm/Pw5LNcH3thDEiv9Q8s24aSbX8A+vYLZ9Xp8uxHyGjhnAxc/nHXNbTjupufw68XRrYs37bqnMf36p/Gw/kxe+XBHUfnx99ake5/0qdU08J1tnZZZhgAw97aXMeP/nvaU/2E/eQazbnimqDKWiqyugYuIJhQGe3JuA2+iwJNpzF3ZPLbulk/5znMKi2yFe6kXCq+Bh9hTnP3TRbhg4Wuh5ffG+k8w7+6Cbz0vAGWK0D4fAtwY3LWRvW2dWU+KCBu09nbN6JS3RArw6x9fiW89JI91IgrQ7bs7sK87Z6yY42dV+taObqmwAgQzg66l1mRSlg+HOfO/pvuERskKfVr3mu1tReXDezAwl0K2FN1hP3kG//Gbl23Os6+oezq6TZpSR5FeGF4p1tsin6eokQpw+Ue+Xu8B8deVVbl93Xm07O0yNMJuiZZ205OrccRPn5UK8Rzn//31+9+yHJedk4/QC2WFSzRQP6zeZl7Fnf+kZQ2jn7rkZgM/4qeLMPW6pxzzaG7tRHc279mNcGdbZ2j+5yKJFOBPr9xu2SfawBnMdsmER4oQqQ+vtiJPYT+lFAdf8xSO+Zl8QIevSN//m7Yidd9eVZYGpOBWFr3NkWkEQT5OOxcz9kz4j2SV8IF54aLfLcFNT672fV6xFPvhaBq4+TOhlKKtQ66Bs2fjFutkX1cW0657Gt/Qha8suNTi1U0AtEiIbZ1ZZHN57N7XrS/AXUj/xnqriea7j7yDFz5oNu0zTY4JqT5GsXiB6ALpNPi6tyvryxznVh9E05jI2qZWHP5/z6C1M2uJRmj3jb+5sQX/86dlnsvoh0QOYsrs2Ex7Nl6wnmSvLsCZJk1IwT552sFDMaihBn98dYOeBz9wov3d0SafwCLrgvbtVWVpQGQ20aggNi5sXuAFDj+AxLLq9NFNlbGlZZ9hjiklxQrwvMQLpaM7b/ToRFr2apPDeCEk0/Y2fKK56j3x3jYAcpMH6y1mcxRTfvwkpo7si7c378Z1cyebTAnD+/bCjnSnZd3OXz+7Fsdys2r5S4Q1iBmFeUD8tnIOk3om/ehJX3l36XnbLW7uxoadBRfLeiEeuNMzXbSqKdD13PCkgRNC+hFCHiaErCKEvE8IOYIQMoAQ8jQhZI3+t38kJfSInQbObI0dWSbAiWGnPHBIHxwwpLe2Qc2uXW5CUHa8oTZjqXwyt7KosAukxGM3WYl/bvw9MA3Lz0CRjLbOLLoj6kY60VlkzJFsPm+xgbd1ZtHW2Y10iuCHZ0wyHWM9Pv5eZQoHe0VsMpnMi4edxgKlsUVLFq9qMr2vbXs6cPDIvhYXWbvJbIBc4w8y0F6sP7sM0cWS3yy24ekuchCTF/zigg7lmBzl1YSyAMATlNKDAEwF8D6AqwAsopROALBI3y4bBS8U/W3rz5JNsmEaOKXUEEqEFD4SCrO25vYyZJp2bSZt+RANDdx2ilF4MBOKXdEfXLoJE77/b+lEDfNyW5wA1/92ZPOBu8vduTy6svmyLPhctAZOYdHA2zuzaOvIoqEmg8P2l+stbho4Y0R/XYBLBCo7T1ycpDqTMgnb3fu6UV+TsdhkxfGenM07ZgQJcVtsWFwZYj0xRSYsUkh69b+3q+v8E60TwsmWo367CnBCSF8AxwK4CwAopV2U0hYAcwHcoye7B8DZURXSC0xwi126fd16fGZuuSOWgqBgo6bUXBldNXChItVk0sikieX6LFlUjbN5sMzZBv735R8DANY2WQc5+VMuunMJXlqzQ9+vHdjXlbPkK6vksg+MeekUO3klCMV28e008NZOTYDzE5zqueh0XR6v29hQA0D+zpgAFkOfVmfSFht2Q3XGMjNQfD0mDdzFm8OrNlkKAW7X8AQR5t0e/cDt7ovf3yDYwGMpwAGMAdAM4PeEkLcIIXcSQuoBDKGUsmVHtgEYIjuZEHIZIWQpIWRpc3OzLEkoWPzAWfez0zyICVqo2GYNnAomFG/XY9RUpVCVTlk0cLYd1SAm745mTOO2KTzf27Ag7Hxs+RZtt76/I5uzCGCZFrdXYmppY7HSy6yBB/ng83lYZty1d2bR3plF79qMsWYmYLaJmu7VaRUow/3V+mwKAtwclrQ6nbII2LqatMWtzSkioux6vJnMa8+l2LERGWKjaxLafAiLAL7nTn7gvEIic80EzM9I1MBL5VnF40WAZwAcCuB2Sul0AO0QzCVUu3O5XKB0IaV0BqV0RmOj/zClXnG1gXcXBCkzZxBSmK9JqXl2nJsGIgqDqnQKmRSxdIXZdlQa+F7OzbEwC1Ce1jCxyGb9Ca+PjcazvZSaY74A8mckq/h7ufVC/Zhh7n1tA0Zf9c+i7O9dpsFZ/y8hm89bFgFp78qiTdfAa7wIcAeYsJKVjV1WFOA1VVYB3lCTscRsEQV4njp7Ku0LIsAj0MDFa9vNIN0jeIx4mVzpFI2QF8B7u3K48sHlmPET89wG3q1YHMQsB14E+GYAmymlS/Tth6EJ9O2EkGEAoP+NZphVguzhW2zgOoYXCjOh2GrgwiCmTxs4AZBJE8t+cemrsDEJcPZxutjvZB+deEqr7ufMl5sPFpTPU6mQkglwNumlO5f3ZdL4jT756RPBBuwHfuGEINP9c3kgLZgm2jpzaOvIor5G1MALXWrTs3G4ZSasnCbWiAsDVKdTeiyOQrnqazJICzZwsQrnuXNkDYZJA/fYAPF1KaweljgwanJ/zMnro1e6s7wB1Qw/OWtvVw5/fXMLdrSZ6x7fyImDmOXAVYBTSrcB2EQIOVDfdQKAlQD+DmCevm8egMciKaFH7DVwYRATtCDAQTgbOEUXV3Hc/GTF44QAmVTK4gfOKnVUXii8wCz0JuQXYxq6bBahqK0ZGji17gO0iizXwK3acrthA5cLfTuYtljMQGRnkRp4TqKBt3XoNvBaswbOd6m7soVrOfUgmKB0Ktv23WYBnkkR5PMUfXsVwhvUV6cts4xlMcmZOUj27gIJcO6cvTaulX5x6unlTAqFoIF7yJvVP5lJk/+WePMMr8ztM5lQyh8+2asXytcB3EcIWQFgGoAbAMwHcBIhZA2AE/XtssE0GFGTYSYU1qpTCs6EAuOtUyrYS90EuERjkg1iFlYPD1eCb2nZh9k3LMJbeigB/lp2Wi6TQ3s7szhtwYv47fMfGsfEM9hEFb7ceziNp70zK72OrHFo7+I1cO/CmJkEgtg6Gfw7PfEXz/vuCWUlU6aZF0pvQQNvsDGhOE31Zulk8TJY4yNq4Nk8RY6aryfrzosymo/rIhfghTJ0ZfPY15XDiTc/j+dW23eu+QayLaR4KJYwA6aJPIXriRp4nrr3dFnDJKuHF/6uEA6AN5XwDUVHV3ANPIpeuCcBTildrtuxD6GUnk0p3UUp3UkpPYFSOoFSeiKl1DodLCJkJhRLLBSqVVJWKdkLyfMmFJhbbbMJxbkMFg0cBAPrq7GjrdP0oroNE4rLTTmQzeVx5q9ewpm/egl7Orrx+TuXYO6vX8a2PR14aOkm7lpaoe18c9nIe3tXDiu37sH8f68yjonl29ORxZUPLseDSwtR9PiK3C7xStHSWLu1TLPZ15XDMT5ClTLB2d6Zw2vrduKsX79kmlj10NJNOG3Bi4558AK8qbUT7328xzH9FQ8sx48ee9fYzksEeJs+iGnxQuE+6Oc/aMZnf/sK2juzjoNbTiYUvs7ydGbz2oICabP2b1lGUHiplFKjvD949F1Lb5EXWl3ZPN7Zshtrm9qMmcYyeAG+w+dErdXbWnHU/GfR1NqB7zz8No6a/yzWNbeZzIKAuLxaYb9s1qSbTd4IXSAR4Fu5ng6vje/aWzCjmDTwGn8aeBSDnOU34oSEaAN/ff0nuOOFgoZZCAdaGK7TbOCcGyE/iOmmgUuE1/B+vdCZzWNnexcGNdTg0nvewDPva9qL+DHd/dJHuOOFD5EmBHkK/PnLszC2scGS57cefBvPf9Bk2OJ+/exavLS2EKyK70bf8fw6AHKTw4NvbDJCEIhT2r/14Nt45n1zeIIdbZ3465tbTPu+ct+bxu+dbZ0Y0qfWcp2lG3bhlQ93on9dNS4/cQKAwsews73TUol/+Oi7GNq3Fl+dMx472zpx+V+W48SJg3H/65uMiHS3P7cWi1drHky3LlqD6+ZOAQB8++EVAAqBhbbv6cB/3bsMv/7cdPz+5fX49ztbsV0QKotXNWHKiL4AgIUvfIg/L9mIH585GTvaOvHsqib8+11tZuRHO9px7yWzkM2bF3Soq07jdy+uw96uHBpqM4YQzaSIyY0QAN5Yvwu3PrvGkwYuxvYB7DX3+1/fCMDstthQk7EoNnkKfOn3r+OMQ4bjM4eNRC5PTT2Gln3duOKB5WjvzOLOeYejhZuSfvIvXzB+b2nZh3tf24ADh/TGL55ajTsuPgz96qoBmOvawhfXoSadwuvrP8FR4wZh/mcONr6vnz+5Gt25PK4+baKR/tZFa7ClZR9m/t8iY9/jK7Zaxjx4E8a5t7+CXtVp/M/x46Tf4J+XbMQfXlmPXF4bME+nCarTKezryuEX500znndHdx4H//hJnDBxMK45azL+8w/mWOKX3bsMVXqP+n8fehsft+zD9P37ow8XlbMmYy/Ab7/oUPwP970AWk/SbiHkoCRCgF/1yAq07O3Gby8+zDaNzAb+syessTco180inM4iuhGef8erjmUSKw8hhVl1J9/yAl69+gRDeDO6c3lcfNcS1GTSeF6IU/HHVzfgmrMmY9H72/HIm5vxm4u0e33kTXMc6Rc+aMaQPjWYOWYg/vH2x9jZZh3gu2/JRry7ZTf2dGRRk0lhUEONSeiLiNfwwqV/XGoZsDxmwiAsfGGdsf3Y8i244qQDuHg0ZuH92rqduPc1LYzBV+eMx6/0xkksKxPegPacXlqzA/3qCh/Sbxavxd/f/hijB9Vj+aYWxwUJVm1rxed+9xq+cMT+uPGJ1cjlKb77yArkqTlswotrduDmp1ajM2uO+1xfkzHWBz1z6nAAwE/PORiHj+6P+1/fZLpWbVUKd774EQBg6n79cMnRY4zYJ1eedACWbdiF5z9oxs+eWIXNu6zBp3iN+ItHjsYfXllvOt7elcPPzj0EKz/eg+mj+hl1eVxjPdIpgu5cHotXN2Px6mb89vkPsaOtE6MG1mNsimBdczuOv+k5w+T16VtecHQJ/OGjBS38hF88j751VehTW2VEA504rA/+uWKrkeaBpZtwwsTB+PTkoQBgRONctKoJmRRBLk+xfqc19PHNT39g2fcLbl+r7oN/7T9WSm3Q1z2+0vg9ol8vbPqk8Fx5EwnL69HlH+NRfX6ECDMRLt2wC/3qqkz3d+NnDgagRenkvWEO278/rjr1IBw+egB+94UZ+PIflxrH2juzGKT7/YdFIoJZNbV2mpY/k61nV4hG6Kw58/6OJi8UwQbOf1Buy1MxhusCfGd7FzYJsx3zlOKT9i68tu4Ti/AGtNl+ty1ei0vuWYp/vbPNiMMtsmpbK06ePBQ3nXuIfi15t/Xtzbvx0Y52rNrW6ii87eI4//vyY2zPGdqnFi17uy028Gn79TNtr9vRjiUf7bT1qf2r3nCMa6wHAKz8eA/69qrCZw4daexjHHdAoxFUat2Odry5sWD7v2/JRqxpasNKF/MIAPzzna145cOduPwvy5HLU3xu1ig0tXZKF6y49VlN6KQl06cPGdkX4/Qe04UzR2H84N4mjficQ0fg/i/PxudmjsI500fg5vOmYvaYAcbxb5wwwfiYf/NcoafIwxSK337+MFxz1mT86sLpxrGDhvbGggum4bwZ++GasyabPGIunr0/xg9uQBNnO1/T1IZde7uRJlrjARTGKw4Y0oAjxw3EiZOG4HunHWQqw6lThlrKddT4Qdi4c68hvAFgYH218fsrx48DYA6yxY6vbWrDqm2tWNPUFniS1WH798fnZ4/CqVOG4fGvH43/OnYs5p9zsHH85vOm4hsnTMAt50/znfcPz5iEUyZb7/mkiUNM+88/fBQA4G9fPQrnTB9h7P/czFE4fLT2nk+aNASPf/1ofPawkZg7bbip9xMWiRDgKeJhUFGcyCOhtiqlT6Uv7LObSs8j2y/zGhjZv7BIshghTWwgrGVLm0wb723ZY3svU4b3RU0mhRRxdrFzWwYN0BZikDF+cANmcgKHZ8ygeun+4fwi0TqU2sfOfvI9zWzDbnNPRzdmjhmAX5w3FXMOHGxKe8M5B2PSsD7SfFgjxjfyTuUENAEIAAcM1oTwumb7hTDMGrgmpGXaH7OBzxozADefNw3TR/XH9WdPwc3nT8O4xgbL7L/qjHn7W7pg5Tli7ECcogvRM6cONxq2udNGYO60Eaa0zAsmnSIghFj8pNmxXsLM0rnTRuDWC6fjlvOnWUID/OCMSbjk6DHG9oTBDbj1wunozwlsABigb/erq8J3TjkIBw3tbVpcRPx+Z4+V1y0v3Pa5Q/GTsw/GL86biikj+uLq0ybicK6uHjFuIK486QCTQjF6YB0ATflgPScZ9dVp3HbRoZZnVF+TwU+5RoIxrrEB1509xdgeKygeU0b0xU2fnYoFF0zHsL7W76NYEiHAiW4nZsjiijjNaGP07VWl5WP4gROTNt+ZzUtbSZlLlegnTvT8DxiiCYSWvXU9XxIAACAASURBVIIdj1JH1yxxuvY7W3bb2kCH9K0FIdqH6KTFTBkhF3g8dhECMyn7dbtHD6qT7h8hEeB/X/4xfv/yeml61sgxDb21Q5vdCFgFZGNDjW0sd7tnMH6wdUyBwQTOOIc0DN6NkGng4iw8oCDA7Ra7FQdDxQZWZh+tEuojUxxkDQjbl06lbJ8VIcRyHT5tddp8rDaTMp4VAEOrFT0wWBq2f8ygemMhbEop2jqzxqIgAHDlSQdi6si+0jKKjG2sN3oNADC4t9UMsV//Qp0c0lsbm6nOpPD90ybi3ktmGu6Tf7xkpvHtyvLpVa3NaB3cx3ysrjptabQY/LNwUhqiIBECPEXcXXC8aOB9aqt0EwqzgRe46pEV2LOv29LyAt41cEIK0el2tfvTwH/znHnFnhc+aMb/Pmgd2AIKU+bdBkTYYJ0T4iw/BiHE+LDFRm30QO8aeKuN9s2Ytl8/w9bb2tFtDBLVCQKiOpPyNNNuzoGNRkPiJMCZzO9fV23q/suQRaCTa+DaPrtA/2K0QHGKvswVsFpoDFg0PakAr2EauP3i3WlCLI0Pn7ZK6BXwi1l8bc54o06J1++vD2oyN8Uxg+qxcededOfy6MxqE7j4+jFzzAD86dJZ8kIKHDN+EL5xwoRCeSU3x9dR/viXjx2LYyY0YsEF0/HFI0djfGOD4VUiG4Rnz0ZsANm7ufEzB+OW86falpUN7paKRAxipggxdcFkstzOD5ynriZjMqGkOBv4En3dwqF9ai3mD5nmbJ3Io2XEGoBdEg3cyQdadIlyWqCVVS7ZUl884xobUJ1OoSuX181Q1jROMbrZs6mrTpsan5H95Rr48H7WD8KNGfv3x/JNLbht8Vq0clqa6NGhlcddgvNeOY0NNbj06DGoyqRwu2BnZi50hGgNjxhLm4d/b+xDrpdp4Po+cUq7XflF7VomlEUhzxQHmbCvq3LXwNMpYrkOn1Z04avJpHDRrFFYva3VZEoR75/1nFheU0b0RTZPsXxTi6GVDutba1oMRGxIqjMpqZLD6vkt509Fi8NyZ9fPnWxrZ540vA+uOWuylu7sKfjdC+tQV53BO1vMKwmx71d8emw/s32L/OrC6fi4Rb78XZQkRAM3m1BkQtpuJiYPU2ZYYyATCDKtVhbHOmcjjFllEyta3kUD9wMrtay3wFNfk8H1Z082rg9o7oo8dgOMQOFjFK8zYUgDzjl0BO69ZCZOnjwEp04Ziof++wjUVWcw74j9fQ3WDGjQNJabnlwNSguLJ/eSCEgvM+1SKWI0PPU1afzgjEk4ctxASzpWT1KEmDxaZOyVxL+Q1ZOGmoINWlo2UQMXdsjMMnYCXHZ95pdMKbUV4CmJDZxPOmV4X9PxqnQK/eqqLXZvdo9HjR+I/zxqjHHvLK+jJwxCJkWw6P0mY1LYMKGHJj4nu4kxTKv/j+kj8aWjxkjTAMDFR4y2FbA84xobMP8zh0jrKXuu4uMTV98ROXPqcPzXceNcrx02iRDgRBjElGmyWQ8CnOiavMwPnCHTauUauPwazFNCpoGL+Vw0S17Z3BYLMbR9FxNKQ03aZOP/4pGjceS4QZZy2V9H+yt+8L2q0rj5vGk4ZkIj7rh4Bm7//GHGyPu1c6fgmPGDxKyk9K7J2GpyvAbOPAzshBJPihQEeC9DI7ZW87xJgFu7vcP71uK6uVrjxzdyTMjIPug6nzZwMeSsrNchChmmTDj1APZ25RxMKNZ6Y7KBZ1JY+AV7d12RkycPxY/OnGSZ1NKntgpjBtVj/Y52YxB7eF/nHpqdkJStSRoGsupUZwhw98Y1DiREgBOT2UQqUG2CWZnygRDMCrKukmQQU6aB21zH0MAFM0w2Ry35NEoGUQC4jlazumVnQjHMEMLkDtkHIk7gMV9HO1kUPKJWaHeeG316VVm6870FG/iBQ3rjgpmj9Hzd89TeqZaQCUQmUHvXZDB5uDawW9DAgb4SF0LC2Yp5DZxpg7JJHCw+tBhUiiE2QKIiwtv92XXEZ81m28pt4Nq+9q6svQZOZCYUcxo30xwPazRYz4S/bjpFQEELAlwyRiLLS8RPefwga+TYsxGPxSHuiYxECHBxEFOmgb+zZTf+vGSjow2crYdJC24oFqEg02rlDYZ5+wZdSyyYUMwaOFuVhqe/zYDHkD7Ozv5uJhQmQOuqMyZhKtMi3t1i7zvNKrH4jKpsNEzxPDd612YsZRK9UPixBv8auPljHDu4AQ/+1xEACj2PVIpIhXEqVWgA9nZl8c0TJ+Azh440hR8WqXO1gZu3LQKcq3t9dFu+OIjJ6rd0EFW//r6uHMQ2hHm8pFIEtcL9ioOC4gpETjClwM78kaeFuDpuiombCSVsZH5WhglFOBZXDTyepRIQbeAyt7GNn+zF9/72jmUFcR4CglfX7cTPdX9rXltj2HmhvPLhDqQJwbY9HdjTkcXzHxRmWX79U+NxnL54rDGIKXih7Gzvws+fMs8MtYsn3KeXs02WfXB2Apw1dg01GZMw9atFsFNFwSkOvlnO8yjA+9RWWbreogDn3TW95JtKFcrNBBoTelWcfZztSxEitYWmOHe7vV05fPNEzY2NzRSUmZ7qXW3gggkl6yDAa7UZn74GMfXz2ztzll5Q37oqNLd2Ik2IRWB7MSPawQSb2CgA2v3y8wBE1zwRu++htBq42ZbPcLOBl4tECHBmA39xTTN2tnU5ugrKAsYcPX4QJg7rjRX6orAsQBM/E5Mx56DBNlPgX7cvH/ebVbaVW62a7QfbzUuZ2QlUtwk4hgbuIpDra9JmE4pPLcJO43UrnxdNGdAaKjGvgfXaR84aJ14D92KaIYRwPRAtD9bgV6UL3hk5zoQi0/BShGD6fv1RW5XCf3ODU4U1Tq0YJhuvAlzQwOurtfC0ndm80YjbNZayunPKlKGY/+9V+OyMkbhvyQbTsYH11Whu7ZTOLRCL60fjFe+J306lNGVibVMbUkTzuz5gSAMusBlotNPAnZSyopA5MVSxXpuogSsBHhjWksuE6AFDGjBtv354dPnHtl4ezN/0goXm+CZE0L8Xfes4jGtswIpNu/EAF+XPzXuEFyx22hfP2MZ6rGtut83XTU65DWKaTCjcHfoNpMPKYdHAQxPgGUvkRLbILxt4NK356SFPflyDFYPZjXlNm034stPACdG01lXXn2raz+5NNi8hk06hJpPy7IUi9iR7VadRrQtwJjDsnrWsSz+yfx3W3nCaqZyM4f16YdW2Vqnfv5jWKUiTHWxyFwtgBmjf15qmNixa1YSZowegd20VnrriONs87DTtIOXxAv8+vjZnPP60ZIPx7sQq7LVOl5rE2MDFLuvCiw/D+vmn46krjsPPzp2KD35yqmUmYDpFcOLEwlKdorlE1MDZzxvPPcSkGXbn8sbA4N1fnIE5B5qXhvPycv/xtaON31efqkVkmz6qn+3MLVk8Br7cADBRnw4u8p1TtLU3eteaBzHZB3KlZMq2/DryyuzWSMkex9xp1unLF80ahSnDzZONWN6su22awGFzWdMkDkKMc5jNlQ1cfumo0RYNnBDg05Osz9ruDk/W38upU4ZJj88aOxATbab8s+f53VO0eCMXHr6fcWzUgDrUZFK46lTtGPPqEScjffvkA0GI+zsQ6+TZerwOFluc1yitg5juYuHSY8YAACYO0+pg79oqrJ9/uvF8WL4bP9FiAp1z6AhrJjDXC+bDTwhw2bFjjf1T9/M2Y9MvvDy49JgxWP6jTxvb4vOTTfqJA4nRwHkBfsCQBiPKGU+NXvFOnDgYd8473KIliYKFcP+z6wgHAWhT7AfUV+P4AwfjUwcNwZ9e2yiUz/0eeO135ugBWD//dADA418/GpN//CQALc7EmqY2UArcwblyjb7qn8L1tAtefMRofH72/vjuIytMcbsvmrU/Lpq1v37P/P1pf79xwgR844QJ+O97l+GJ97bZllnUZAEY5XZCNHUcOW4gPnXQYDy2/GMcOW4g/vzl2abj6244DWO/9y/TvtqqtOVaMhPKLedPxdnTRmDs9/4FSrV7PHv6CENgAcDg3rVGXmwCDzPNpAjB+MENWD//dEy99iljEpddo3zg0N6Oz+CP/znT9hhgfn5Hjh+E9fNPL0THJMT07i4/YYLlnr86Zzy+Ome84zW0vLS/owbU4YXvzMHW3dokEzY/4akrjjWiNorX8KLxnjBxiGtdYPkO71treBKJLLhgOhZcoAXpuvEJLT59ihB877SJ+B4XejYK+O9WfAZsc/bYAfjLZUdEWo5iSIQGLsZCsfu42EAK8xvl7aGy83iPBS0995tL16VPBWbdWVFge+ld8YMg/HRlXpOyM3GIGj9/OTGeiwhfVvH+7cp9tO7HzdKnCMHUkX0x1mOcB/H5pAjBQUM1rfRyTqM2jusnXDx7f1/5srz5af9udnJ2PMcNYhaOmfMtFWI95fcHhZXf6NH0rpUeF38D4Xl9sGy93gd7v169mIrF7tvXtpl6F0/TCSMhGrjZ5mhXIZgGLhsR184TdwjC0EYb785pk3AKXXVRELq/ZN5myZtn+OvY2QB//6WZeGz5Flz+l+XS+3C6vKkCejjvt58/FKfo5gHjAwTwGGcCckPWUBw4tDc++ulpts8qiGYPFARUigA5ybWtZdP+Ghp4ij8mF+ZJRHQBZc+JReIzC3Dh3JAkqKEAeGwPvDbCYeGk3LEtr2UvFwkR4GYN3O71MsHtddSawPwS7VrkrmwOXdm84ZMr1m/RHjmgvhr96qqw6MrjMOZqzTTA2xz59Pxvp5Fux8rGbfI2f/GY9TzZk5Rcx+cHZWknQ/owZWezSIFaQ0U9DwDn8hINnEsX10ErrzAhzEdS5BtQp55ZaGUwNGpv+cvKFiV2754vg9LAQ0AcxLRrFQ0N3GWCC79tNkdwv7n93fpq6gUTimiKMV/nje+faLke700gs0sD9j0HsTyWY3p+gxpqsFBYtcj8obrnabq1gF1a8TmH9UHKBIE40OrlWoSYY6GIeQHx17zcEE0ogKisuPc2jj2gUX7AI+zr8irASy00vSg3cW/HEyHACSGmCR1uNnA7DVxiQbFcR3aNLn01dWZCsQ6Gmnd4cSWUXZNN+Zb5GDvZLNlWJmWdpMHfpdULRyIQJdf0W4e9NBRBkL32ggnFu7Ag4G3g8vwTr4EbnSf5fbhp4KuuP8XWn90rfjtwpX7mdu+eP1Yqc05QEiLAzULN7qGmdQFop8nKBh/NHy1/sPCzszsnDGLamzCKwUnwOw+42JfDSQO3GxQ08pXs84L1YwjnARWEdCG6IuvY+BkwSxFiaOBEcr9e84kzBQ3c+bj4mxHG7Ee/CkCpTCcMXqGxH8SMN4noKLKJPAzbh6qn8W5CEc0m8krNFuU1BjGFAtgt9eUXZq+UxdmQacaFY/baJzHfoG2ehfT8daz7vODN1h4APRs+umDBbuq9y0sI70ZY2O80sJc0jEBkthp49PdaMGt5u0CpG027b1/b1oh7PUiEBm6xgds8VBakyrsJhdi2wvxvFk60WtDAe9dm8MQ3j5UuJcZYcc2npQJZhtPov5PN0qneO7sRygS+9bhfm6SdT22xmOy6+gTOtCC4vdnAiTGIabYRW6+VVNxMAIT7RKISnH7MWn7ShYXdWBRflrj3xBIiwIkgwJ0fql38YKngsxHafFKmgbMofLxpwUl4AzCWCPOCnbbkVDZ+W3a643nS9FaB5l8Dd94OCstG5sXjx9yTIkCXZBDTySshabi7U5ZOA/duA4+mHF6uZ2cWjbsGnggTijiRx65CUJ8mFECwe9qYUHa2acuOscBCQU0LbrBV7WWLEdt5S/DbUoHM35MYhU4ipmSmGr/3aWkoQxKHrPi8AC/4GnvXmJxsn2K+ScWtjpbCjdCv+2jJNXD+t40GHvemPCEauLeJPAzbeMyWfIlU4xR/v/LhTgAFE4pod/XKG98/0XFl+qn79cPjXz9aGkvDqbI52RplNm27bS29VQv1K4AtbpYhqQmsbBmTANePwfzXCTvhZff+k4jbIJwYNTAK/M6sLPUzT5nMZ8nUwBMiwMWp9M7p7Q7LBJ9ZA3dGdCP0+3LtVuBhpFPEdiV5J/ssE7Cy4pgrprySwiaF35l0tuUL6ctk2dhNhJJdW56PvKfl5pmRJNzKLxvriKoMsbWBOx0L2PssNYkwoVgHMYM9VetIM3EUjCLMjZD40ve84+RG6GSfLdgarec7T+SRpbdqpMWaQMJ6SqwcJg3cIsA95GPzTEz7E/Fl2FNwr5Q/kFI0VixXr4pOyd0IHe7b7yzScpGIaiquielmA7c7LtfA3e2hDDGYVdgVznECkKMGrv+VatT23USZkJJpZv4HMf1rxd7y1f9KbODGtoeXwj8vL9p4EnHzwS7NICYx/XUjrBgsXnF6x07fVJxIhAD3KhDYYgB2S5LJBJ/ZS8P5bVVnzG6EYb9cLxVKdt2Cpiw5z0EDl50hu47fLnaQaI3e8rVq4IbvvJ98hNmbDPO9x/zLdcGt/KWMheI1+3L6gYsUGsB414OE2MDN23Yv+tsnH4hp+/XDEWMHyjOSauDcdsohMTg3woi6V55NKDbPw9Wv28YGzs9slPnG+r1L+xH94pDZwMVehDc3QibA5fnLjiUN13Eih/oUFn6/E1Zm6qs5Do5jh9dn41MuPGvghJA0IeQtQsjj+vYYQsgSQshaQsgDhBD5EushYBUI8nS1VWmcOXW4/eQF2R7idNyM6IUS9rv17AduZ0KRnedgIpK55ckEvl9hFlWogYIXijUcLzG2PeQj5Cfmz+ebVPz0EqPTwP3Vn9IPYjp9b/7MP+XCjwnlcgDvc9s3AriFUjoewC4Al4RZMB47gVV0PsTZRiwieqGE/XKdBs4cJ5k4aDqOkxVgraR8iqABfazvKzoNvBgvFKegW5WigXt59lELcL8LOpQKp2L5UQjKiScBTggZCeB0AHfq2wTApwA8rCe5B8DZURQQCG9QzC1KntvLYppfYTAtUDFscQxmxf22ex7SQUxH04t+XVMa62+/TzuqmZhOE3lYp9tL1bDr2jtNlkoafsofmZAipj/uyUtuA7e/XtBInKXGqwj6JYDvAGCzUAYCaKGUZvXtzQCkq5YSQi4jhCwlhCxtbm4OVkiL4An2WMWzCBGWVHN5Xcw2V/C7Dvf1OplQ7Kb8C4espzlo4LKY0TK3Ov8auPN2UNjzdtLAvUUjZH/tTT1x/3DdMO7NU4MWtQnFW/6lfuZebOBxN6W5CnBCyBkAmiily4JcgFK6kFI6g1I6o7ExWID4sGyq4tBIioieB87nZ4UY0mFrLk5uVM6DmOyvswnF7v6ITZqCicW2WFKidiN0monpzQZuY0KpKBu49tfLXUSlgfvtqZY+mJX9MT8NYDnx4oVyFICzCCGnAagF0AfAAgD9CCEZXQsfCWBLVIX0OojphhgVkBD30fjTDx6GScP7oDObx8H6LMmoBjgcBzFNv4UGzXGwUa5da9tWjVaW3u/zdhocLAYiKa9oQvEazAqwNpj8VtIn8vgRhtFP5PGWf6mfuaPbbkI0cFcBTim9GsDVAEAIOR7A/1JKLyKEPATgXAB/ATAPwGNRFTIsjS4vSHBxJqbMJDJ9VD9cesxY83nE/DcsnBd0sBfETuUxa+DynkzaJu+CEuLThCJuh2VCYeV1HMT0ko+8a+/HnBZ3CsG9PKSNzSBmfJ55T1jQ4bsAriSErIVmE78rnCJZsdMci8bBhOJklnCKPVIMzn7g3PVtvHKk0QUdvFcMDckmqE/QCUvWBtff+XbIbOCWuuDJC0VerpRZgicaP14oUclNv0Kw1IOYTnIkqoijYeNrIg+l9DkAz+m/1wGYGX6RrFhsw0FNKMI2gfMgn92looqT4HlJNZuDUi8U7rfdtPOUXd4B7zOqBldqA7dM5PGSj1wzjPvH6odYmFB8muD8NDph4GXmc5x6BTISYemzxPAIaRRTy9deQ9WuJdnno3vqB2ebnL3W6TRg5Tj4qf9N26QJOpDjZFsuhoIJpVBtxXEDb37gLG1IBYshfupm9OFk42lC8TKIGXP5nQwBHpZfsThFV9TApRqsg1ZeUg3cdsNZY3HsYbAPzMYkEVZPI6yucWHQtbAviA3cyMfjoHESidNMzLhO5HG8nmFCiXdNSIQAt1tw1C9SLxTTtkRYOwj1knqheBjElJ9nf8zNTzeorT/qqfROs2c92Xxtzq0k/AnwaMrgt6dT+vdhf71Km8hTVsKyqVoEOIhrpZEdDWhZcMV5Kj1/fe8NmvOSahr2C/ta93khKhu4IRAcNHAvl5LlU2n4EcpRCU6/4YhLbUJxekZRjXOFTSKqsFWjCyjARRMKcRfCTpNjSjuV3oMG7tKDsDvPNl6Ki4ZuW9aQTF4iskGuYDbwYPeVJGS9FTuiDifrNxphqXCSI0EnsZWaRAjwsASCVQN3f0Fyzw7vH4cfvEwskF3XS0wH2XmyiTxOAt8rYTW4IrKPiv1m79ZLo+pFsJQmoGl0+Ok9RWZCMSaYeRXgMdLA2YpGpSlKYBIhwKOaSk8IsRXChlIrOR7VVHrPboS+useF33bemHZCPmgDFZV7niw6osWE4kPjjLt2VQxxcCP0a4Ir9ftwvh6rI/GuJMkQ4AGC9suQDWK6IU1DfNZMjzh7Rci1ZMDbhAQ9E3OeksHYMDRw8bTQeiqG6aOwKy0IYz+vpJJNKH7Me1E9Bt9LqpX4fXhZEzPuVSQZAjy0LrmzG6H82vb7wn63jsGsuDdlt7KOnMJBu55MykZoB33MUYeTNbVJognFQ6F7ghuhH+EZn4k8JRbgTsc8mNniQCIEuHUiT7B8rBq4e0bS6ell+LwdBzGdzjPZzuV5mispr40Hu0/rSvHh2sBN+wINYpr/ViJ+bi36FXm8auCRFMPhek4auN4AlqowAUmEAPfj9+yE1QbuIS8HDbyUmG3g3jVw88QceUPIe+cEtbWbyxOtDdz52l7y8SdYkoivRZ4jegz+beClfR+eptLHfLpuQgR4OBodtUQjtNemDS1NVp4yvFQ7Mwfg3CPgj3gZDJalF5+bGxZNPywN3JNw9p5PJfuBMwnu5clH7QceVw3cqVg9IRphyQhtIo+w7aSB+7GplgZ704ZjY+NgQ5H5Cps9UoJhaSgC5iPiyeTlI0183m10lNWN0KFeSstRYgnupeeqvFBCIZyHaFUkiWsFlx0vx4cf3JxR+G1nirIzoQS9z+iiEbrn48kGzv7G/OMshsLyf+70VBu4lxhCca8iiRDgkWrgbiYUmZmhDC/Vy4CLG17ihji5K3rF6uYYLB+3fGV4C2al/U3H/OMsBj9Wr8hX5PEoZUpvA3c/FvcqkhABLh9884vUBu6mgTtM5AmL6aP6uaZxuqRjV9AUaVB+np3QDrx4tBrELDusqnsyKUUWTtafGSJOfuBJMbP5WtChXFgm8oQkQVPE3SFQPtAX7ku9/8uz0dmdd0zjZcTc7ZhfL5TCcX9EPZXeMY0PN8K4f5xhUF4Tivcy8OlLhdP1kmJCSYQA9xN9zwn5osb+rs3OC5PaqjRqq9Iu5XA6Fsy84ncJNq+I54UdjdAJP8Gs4v5xlorIBKdvG3h8BjELcXfiXUkSaUIJLRqh7kjohOxo3F6qs3Av/PbtRhjwyxZ7TGE9Lqfnzsxjnsws+t9K1sD9+YFHrIF7zL7Ur8PZhKL/LVFZgpIQAe687RU/GrhTOMly+PY7CVN2xE0gi8floXKL18DDGrOw5uuexk8wq4r2A9fxIhSjEpz+11ItsQbu4VjcG/lEVOHQohFK1BJXG7h0ELP0L9Xxih4GYwBv/tmRDGKGpMc4fnBGd91DPj3ABu5n8lXUXijlLkcx14t7FUmEALe6pYVkQvFkU3UvTylw9DRhg42yBooXyDbnmdJ7vKYT4mmheaE4SGcmsPwEb6poAW788v48wsavCS5OsVAKaUpQkCJIhAAPzQYeZEk1qQAv/Vv1OxgpO8+LCUWmsfucSR9a6AMRL7n408CLKk6sKbgRuqeNeiam9/TxGcQspIl3JUmkAA++Kr0ZQrwIBYmQC3b5onA2H5j/2p3nxT/bSWP3SljBx0TUVHrv9K+rAgDs17/ONW1ksVB81qA4xUJJColwI/QTvMmRQG6EsvKUwQYe1A/c4aBUA+d+B73PsExebvnK8DMT08tEjqQya+xA3HHxYTj+wMaylcG/H3ipBzGT/Y6BhAhwq0AIlo/MjdDtJcoqVdxs4EF9xOWDmMWr4NHNxAxJAzfyK7JAMefkyUPLev24e6F48ULyG4mz1CTChGIJ2h/wyxPfRcqLBi7ZV5Z44I7HiG0av4LfdoV6H0Q1E9OPdu2cRm5C4bfi/uEmAf82cO2vqGhFRSVo4IkQ4NEtamyf1tmuHK9BTKfi+A2CZV7UOBjieaEFswp5Kr3TItKK4vHbcJc6nGwlvP6ECHDzdlABatWqgoWTjZsJxfAWkZ3nlKfLzqATXSwzMcPyAw9JA1dT6UuDXwFZ6tcR1CwZJxIiwCMaJSfuWoKbq12piGIQU+YmaFrUOOAnFZUNPKwFegs2cHNaZTQpL3GKRpgUEiHAw3rOVv3bvdWPjQ3ci7lHcsyv6cUUzMqwSfojqhV5wg8nW2SBFKFS8FopzYuphNefCC+UsFrmvGRVencTijVB3KbSFztjMgzf71JQGJcguGveDOS4F8p+eYqFoqstTg1NJWhn5cbvE4zTosZJwVWAE0L2A/BHAEOgfScLKaULCCEDADwAYDSA9QDOo5TuiqKQoT1oH4sa82ks+8rw3sOYiWl3jH8sSajTlFKcMHGI9JgXu31SQoUmHf89t0iK4XA99wvG3RnJiwklC+BblNJJAGYD+CohZBKAqwAsopROALBI346mkFGZUIi7wJL7gZfDBl6aY0nVSuzs2tK0epKMsqGUhPiuyFPSy0WCqwCnlG6llL6p/24F8D6AEQDmArhH/2Bl6gAADiZJREFUT3YPgLOjKmRYAlMaC8X12pJ9oZTGH0Fd6LyYXiqhIrNX68cLpSpTATdeQSgB7h9fg5iEkNEApgNYAmAIpXSrfmgbNBOL7JzLCCFLCSFLm5ubgxUyNA3cezRCIvw1lyduGni0JpS4TGrxUgxvnira30xPCAieIKJam9P2egHNknHC8yMjhDQAeATANymle/hjVPvCpZ8XpXQhpXQGpXRGY2OwuAyRaeAB3VDi5wce7Dx5XsmouHZ4KT1LU51RAjxOlD4eeEkvFwmeajAhpAqa8L6PUvpXffd2Qsgw/fgwAE3RFDFEDVzmhRIgFkpZVuQJqC341c6TXqe9xXjWTShp+7Rx6XX0JEpd95KiZTvhKsCJJgHuAvA+pfRm7tDfAczTf88D8Fj4xdOIcsWQILFQyiHmInEjdPEDTyJ+6kpPN6Fce9ZknDl1eGT5+20DS131KkED9+IHfhSAiwG8QwhZru/7HoD5AB4khFwCYAOA86IpYoQTeYgHC0pMNPCgMzEd84xJrHOveKkHXtLkdMniZEJJekPmhXlHjsa8I0eXuxjlowJesasAp5S+BPtbPSHc4sgJSwMXu8XJWpHH/ljQ4rgtFxdXIeZlNXEnsvoEICcTiqJ4/Faf2kwaw/vW4tunHBhNgQSSPt4D9LCZmNJV6V2v7W1f1DgLU8L97ydPv9eJP17qSi6nVYSebkKJGt9L8aUIXrm6JDohAG/fS9xHQhJRg8MSmF8/Ybxp24sNXPaa49ZyBy9OvO7DDS8Cwcu7MTRwBxPKRbNGeS6XIpk4OgYk5NNIhgAPSYKfcchwrJ9/emEHsR+Jdgw5GrOX6xRO1vk8b+nipoVIPUT0XV7uKZvPAwCqbBLfd+kszB47MGjxFAkhbopYEJIhwCPzQnG3ocRlIo8TgQcxY3YfoeBlENOwgcurfwU+FYWMCnjRiRDg6agEOAkYCyWS0gTHKZys43mhl6SM6DfjyYSSczahVGTDprBQCW6EiRDgUU2xTZFgsVBip4EH9UJJxNv3iGFC8TCIyTRwmy84Zq9XERGV0FAn4hOOTAOH+0uU+krH7L0HXjknoTq48+xS9/OZH7gyoURL3MZORJQGXiKiWnzW20Qeb/vKSogzMaXZFvkllvJ5eWmUsjltEDNj4wde6sV1K53YfS86SVVgeBIhwKOqACToosYxe/GsNH6fU6m6kCUJK0KEvw4wN8JqpYGXhLiGlYlrw+KHRAjwqEwoXr5UmbA21u6LSQWQhYX1QkyKHw4+7j3n4gcel/eqiBYv7zmujQ8jGQI8UhNKMqbSOxF8Kr3/e/fCiH69gp0YAn6m0tutyBO395t04vo4nSN8JoNECPCoPigvMzHlXiiRFCcwhTUefZ4X0X2MH9yAl747B589bGQk+Rcb6lX5gSuAynjPiRDgUeGlYZB7oQQzWURF4HCy4RbDxMj+dSVdsu2o8YMA2Nu1eYyZmB7SKiqXuLkDByERwayiwosGHjdtW4aaiQn88oJp+LhlH2qr0q5pWTArFY2wZ1MJ1b9HqyBBbeCxIyI3wiRRW5XG2MYGT2mzLiYURc+gEhSYHl2DvbgRJsFSZtjAfZbVa2pxMWi/hG1qKvbDc7OBK8JBLUsXPT26BjtN5Cml/bZYmJnHr6DtqRNW1IIOpSVu8yYqCSXAXSR0EgY6gmqkpbqzuD1CWz/wuBW0Qii2B6ewp2cLcA+6gdPxuHzvQbuqbt40lao5FeKB9+jqr3DCiLEf78anR9dgL+Fk4yKkveDbBu6SvKFWc1JqbKgJVJ5B+nm9a6sCnS/C8hnUUF1UPiP71wGIboKYQqNfnfaeBtYX976ipk9tcp3xklvyEAgajbBScIuhcuyEQbjp3ENw5tThgfK//MQJGD2wHqdOGRqsgAInThyMn517CM4KWB7GfZfOwlsbW6yr0qtBt1A5Z/oI5PJ5nHNoNBO6wuDuL87AAUN6l7sYgUmkAK+vcff19UIluBEBwYMFusVQIYTgszP2C5g7UJNJ47zDg58vK895RZSHMaRPLU4JqVFR2JNKEZx/eLzXFv3UQUOk+3vXaKKxoSbeIjLepZNwzvQR+NzMcCpFZYhvjphMpU8s6oEodOYdORqEaH/jTOIE+KXHjEUmJP9dp+81kZHKfEcjDBZDRaGodKozKVx6zNhyF8OVxA1ihilsKsWEEnwqvfY3dg2RQqHwRI8W4MUSl7Io+atQ9EwSJ8CTMLGmbKiYKApFjyJxAlzJmvBRJhSFIpkkT4CXWILHfSaWQqHouSROgCsd3IrSoBWKnkniBLiy1yoUCoVG4vzASzWI6TSFfvLwPpixf3/86MxJJSkL44tHjsb+A+t8n3fZsWNd44dce9ZkfNjcFrRoFcH1cyfjun+sxMRhfcpdFIXCE0UJcELIKQAWAEgDuJNSOj+UUjldM+oLeKC2Ko2H/+fIkl/3mrMmBzrve6dNdE0T9xlnpeCQkf3K8l4ViqAENqEQQtIAbgNwKoBJAC4khESukpbKhHLt3MkYNaAOQ/vWluaCIRCHxk2hUJSOYjTwmQDWUkrXAQAh5C8A5gJYGUbB7ChVdMA5Bw7GnO8MLsm1FAqFIgjFDGKOALCJ296s7zNBCLmMELKUELK0ubm5iMux/IrOQqFQKCqCyL1QKKULKaUzKKUzGhsbi85PCXArylddoeiZFCPAtwDggzOP1PdFSqUEoIoC9WgUip5FMQL8DQATCCFjCCHVAC4A8PdwimWPklH2qAk9CkXPIvAgJqU0Swj5GoAnobkR3k0pfS+0ktmgtEwrlbzsm0KhsKcoP3BK6b8A/CuksnhCRSO0omzgCkXPJHlT6ctdgBij2jaFomeROAEehgQ/9gCrN8wxEwYVn3GZGDVAm15/8mR/C/UO6aNNUjr9kGGhl0mhUEQPoSUc+ZoxYwZdunRpoHNHX/VPAMAb3z8Rjb1riipHNpdHd46iV7W2un1Hdw6ZFAltrc1y0NaZRX112reXTntnFnUBzlMoFKWDELKMUjpD3J+4YFZhyJlMOoVMurBdW5W2T5wQGmqCvcr6gOcpFIrykziVUw1iKhQKhUbiBLgS3wqFQqGRPAGuJLhCoVAASKIAVzq4QqFQAEigAFfyW6FQKDQSJ8BTSoArFAoFgAQKcOWvrFAoFBrJE+DlLoBCoVDEhOQJcCXBFQqFAkACBbiayKNQKBQaiRPgCoVCodBInABXCrhCoVBoJE+Aq2FMhUKhAJAgAc78v5UGrlAoFBqJEeAq7KlCoVCYSYxU/NtXjsSzq5pQleBFFxQKhSJMEiPAxw/ujfGDe5e7GAqFQhEblDqrUCgUCUUJcIVCoUgoSoArFApFQlECXKFQKBKKEuAKhUKRUJQAVygUioSiBLhCoVAkFCXAFQqFIqEQSmnpLkZIM4ANAU8fBGBHiMVJAuqeewbqnnsGxdzz/pTSRnFnSQV4MRBCllJKZ5S7HKVE3XPPQN1zzyCKe1YmFIVCoUgoSoArFApFQkmSAF9Y7gKUAXXPPQN1zz2D0O85MTZwhUKhUJhJkgauUCgUCg4lwBUKhSKhJEKAE0JOIYSsJoSsJYRcVe7yhAUh5G5CSBMh5F1u3wBCyNOEkDX63/76fkIIuVV/BisIIYeWr+TBIITsRwhZTAhZSQh5jxByub6/ku+5lhDyOiHkbf2er9X3jyGELNHv7QFCSLW+v0bfXqsfH13O8hcDISRNCHmLEPK4vl3R90wIWU8IeYcQspwQslTfF2ndjr0AJ4SkAdwG4FQAkwBcSAiZVN5ShcYfAJwi7LsKwCJK6QQAi/RtQLv/Cfq/ywDcXqIyhkkWwLcopZMAzAbwVf1dVvI9dwL4FKV0KoBpAE4hhMwGcCOAWyil4wHsAnCJnv4SALv0/bfo6ZLK5QDe57Z7wj3PoZRO4/y9o63blNJY/wNwBIAnue2rAVxd7nKFeH+jAbzLba8GMEz/PQzAav33HQAulKVL6j8AjwE4qafcM4A6AG8CmAVtRl5G32/UcQBPAjhC/53R05Fylz3AvY7UBdanADwOgPSAe14PYJCwL9K6HXsNHMAIAJu47c36vkplCKV0q/57G4Ah+u+Keg56N3k6gCWo8HvWTQnLATQBeBrAhwBaKKVZPQl/X8Y968d3AxhY2hKHwi8BfAdAXt8eiMq/ZwrgKULIMkLIZfq+SOt2YhY17olQSikhpOL8PAkhDQAeAfBNSukeQohxrBLvmVKaAzCNENIPwN8AHFTmIkUKIeQMAE2U0mWEkOPLXZ4ScjSldAshZDCApwkhq/iDUdTtJGjgWwDsx22P1PdVKtsJIcMAQP/bpO+viOdACKmCJrzvo5T+Vd9d0ffMoJS2AFgMzXzQjxDCFCj+vox71o/3BbCzxEUtlqMAnEUIWQ/gL9DMKAtQ2fcMSukW/W8TtIZ6JiKu20kQ4G8AmKCPYFcDuADA38tcpij5O4B5+u950OzEbP8X9NHr2QB2c12zREA0VfsuAO9TSm/mDlXyPTfqmjcIIb2g2fzfhybIz9WTiffMnsW5AJ6lupE0KVBKr6aUjqSUjob2vT5LKb0IFXzPhJB6Qkhv9hvApwG8i6jrdrkN/x4HB04D8AE02+H3y12eEO/rfgBbAXRDs4FdAs32twjAGgDPABigpyXQvHE+BPAOgBnlLn+A+z0amp1wBYDl+r/TKvyeDwHwln7P7wL4kb5/LIDXAawF8BCAGn1/rb69Vj8+ttz3UOT9Hw/g8Uq/Z/3e3tb/vcfkVNR1W02lVygUioSSBBOKQqFQKCQoAa5QKBQJRQlwhUKhSChKgCsUCkVCUQJcoVAoEooS4AqFQpFQlABXKBSKhPL/m7Gb6oL87o4AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_reward_per_episode = []\n",
        "for i in range(0,10):\n",
        "  print(\"New Episode!\")\n",
        "  agent.reset()\n",
        "  done = False\n",
        "  for j in range(0,25):\n",
        "    if(done == False):\n",
        "      print('Available Actions : ', env.getAvailableActions())\n",
        "      action = agent.ChooseAction(False)\n",
        "      observation, reward, done, _ = env.step(action)\n",
        "      print('Reward: ', reward)\n",
        "      # print('Action: ', action)\n",
        "      # print(\"Visualization Graph\")\n",
        "      # env.render()\n",
        "    else:\n",
        "      print('Goal Reached')\n",
        "      break\n",
        "    print(done)\n",
        "  total_reward_per_episode.append(reward)\n",
        "plt.plot(total_reward_per_episode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ALHjDmKjTScZ",
        "outputId": "51963038-78ac-4b5a-e027-75508ed1d394"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  5.5\n",
            "False\n",
            "Available Actions :  [0, 2]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6.0\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  12.0\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  62.0\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  5\n",
            "False\n",
            "Available Actions :  [0, 2]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  5.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  11.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  61.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  50\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  5.5\n",
            "False\n",
            "Available Actions :  [0, 2]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  11.0\n",
            "False\n",
            "Available Actions :  [0, 2]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  11.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  17.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  67.5\n",
            "True\n",
            "Goal Reached\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe93dcd29d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent.q_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYay6RDZTSpJ",
        "outputId": "6caf5121-7a1e-4442-a637-c44c69f38b52"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(0, 0): {0: 0, 1: 0.07050177780510004, 2: 0, 3: 0.00599670109975254}, (0, 1): {0: 0, 1: 9.99989992600594e-05, 2: 0.004928059585372055, 3: 0.001099408533133062}, (0, 2): {0: 0, 1: 0.1476793533023757, 2: 0.09767397477079354, 3: 0}, (0, 3): {0: 0, 1: 0.24441292014157273, 2: 2.0661998575438494, 3: 0}, (1, 0): {0: 0.005324604082719635, 1: 0.005373941264880942, 2: 0, 3: 0.0002499958901808303}, (1, 1): {0: 0.00029995049395488524, 1: 0.0003998970009073402, 2: 0.0007495281836106055, 3: 0.00044985851359505144}, (1, 2): {0: 0.0006001547257693008, 1: 0.007745491980600451, 2: 0.004284825100728604, 3: 5e-05}, (1, 3): {0: 0, 1: 5e-05, 2: 0.002543659839315987, 3: 0}, (2, 0): {0: 0.00611629518060334, 1: 0.006116354239665699, 2: 0, 3: 0.0035891636452505676}, (2, 1): {0: 0.00010000199693587148, 1: 0.0004998200241848725, 2: 0.0005497720454388543, 3: 0.0005997035888069227}, (2, 2): {0: 0.00035005990918742007, 1: 0.005522470712225982, 2: 0.00030001726760442107, 3: 0.0004999659320513922}, (2, 3): {0: -0.00119994, 1: -0.0017998200060000001, 2: -0.0041987402099790015, 3: 0}, (3, 0): {0: 0.012199328026728986, 1: 0, 2: 0, 3: 0.00029992500999925}, (3, 1): {0: 0.0001000348560463465, 1: 0, 2: 0.006313751705720022, 3: 0.0008494660754930785}, (3, 2): {0: -0.003498960170831349, 1: 0, 2: -0.06261034676457453, 3: -0.0029993848732626396}, (3, 3): {0: 5e-05, 1: 0, 2: 0.00039986002799650023, 3: 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent.value_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4k3PZhETS8e",
        "outputId": "c7bafd48-f92a-42a2-9914-d934c94a3ef0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7.05017778e-02 4.92805959e-03 1.47679353e-01 2.06619986e+00]\n",
            " [5.37394126e-03 7.49528184e-04 7.74549198e-03 2.54365984e-03]\n",
            " [6.11635424e-03 5.99703589e-04 5.52247071e-03 0.00000000e+00]\n",
            " [1.21993280e-02 6.31375171e-03 0.00000000e+00 3.99860028e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper Parameter 2: \n",
        "Epsilon Value: 0.3"
      ],
      "metadata": {
        "id": "5lu9znovSztr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = SARSA_Agent(env, gamma=0.1, epsilon= 0.3, alpha = 0.0001)#0.4,0.8,0.01\n",
        "reward_per_episode = []\n",
        "obs = agent.reset()\n",
        "for j in range(500):\n",
        "  obs = agent.reset()\n",
        "  # x = np.random.randint(0,3)\n",
        "  # y = np.random.randint(0,3)\n",
        "  # env.agent_pos = [x,y]\n",
        "  # while(env.agent_pos[0] == 0 and env.agent_pos[1] == 3):\n",
        "  #   x = np.random.randint(0,3)\n",
        "  #   y = np.random.randint(0,3)\n",
        "  #   env.agent_pos = [x,y]\n",
        "  done = False\n",
        "  action = agent.ChooseAction(True)\n",
        "  cummulative_reward = 0\n",
        "  for i in range(15):\n",
        "    if(done == False):\n",
        "      old_state = env.agent_pos\n",
        "      observation, reward, done, _ = env.step(action)\n",
        "      new_state = env.agent_pos\n",
        "      new_action = agent.ChooseAction(True)\n",
        "      agent.Learn(old_state, action, env.immediate_reward, new_state, new_action)\n",
        "      action = new_action\n",
        "      cummulative_reward = reward\n",
        "      if(done == True):\n",
        "        print('Reward: ', env.immediate_reward)\n",
        "        print('Action: ', action)\n",
        "        print(\"Visualization Graph\")\n",
        "  reward_per_episode.append(cummulative_reward)\n",
        "\n",
        "plt.plot(reward_per_episode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IivfBhydTUxJ",
        "outputId": "d0201f49-69b4-459d-b45b-d9388024d469"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe93d531d10>]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_reward_per_episode = []\n",
        "for i in range(0,10):\n",
        "  print(\"New Episode!\")\n",
        "  agent.reset()\n",
        "  done = False\n",
        "  for j in range(0,25):\n",
        "    if(done == False):\n",
        "      print('Available Actions : ', env.getAvailableActions())\n",
        "      action = agent.ChooseAction(False)\n",
        "      observation, reward, done, _ = env.step(action)\n",
        "      print('Reward: ', reward)\n",
        "      # print('Action: ', action)\n",
        "      # print(\"Visualization Graph\")\n",
        "      # env.render()\n",
        "    else:\n",
        "      print('Goal Reached')\n",
        "      break\n",
        "    print(done)\n",
        "  total_reward_per_episode.append(reward)\n",
        "plt.plot(total_reward_per_episode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KZlNuorVTU9Y",
        "outputId": "303f9762-e55a-4fff-f21b-6ec9094de48b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 2]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  1.5\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  2.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  2.5\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  3.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  3.5\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Reward:  4.0\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -1.0\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6.0\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56.0\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 2]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  50\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  7.0\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  57.0\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  1.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  2.0\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Reward:  2.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -2.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -2.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -1.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  4.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  54.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Reward:  1.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -2.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  3.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  53.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  7.0\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  57.0\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56\n",
            "True\n",
            "Goal Reached\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe93d72f050>]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent.q_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VMBKCv5TVJJ",
        "outputId": "1e75a6a8-2617-4f4b-9b8b-a9198da596c2"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(0, 0): {0: 0, 1: 0.013981116369767413, 2: 0, 3: 0.02245057087556356}, (0, 1): {0: 0, 1: 0.003985276725330408, 2: 0.003439294313163096, 3: 0.0022455794264962478}, (0, 2): {0: 0, 1: 0.16870693235705503, 2: 0.10711784271762433, 3: 0}, (0, 3): {0: 0, 1: 0.15476772459275992, 2: 2.0230378592941243, 3: 0}, (1, 0): {0: 0.0028924957772312144, 1: 0.002643844166286665, 2: 0, 3: 0.0026937453029988504}, (1, 1): {0: 0.0012986243148090523, 1: 0.0013983038048543497, 2: 0.0010990533874292532, 3: 0.0020961684829396477}, (1, 2): {0: 0.00264546857014302, 1: 0.012699082901384183, 2: 0.001199320027099864, 3: 0.00015002187970906763}, (1, 3): {0: 0, 1: 0.000149986500405, 2: 0.0018466943543541555, 3: 0}, (2, 0): {0: 0.008090158613757682, 1: 0.007499140757416516, 2: 0, 3: 0.0003499847457829237}, (2, 1): {0: 0.0006996165994880882, 1: 0.0009492772935675195, 2: 0.0016974639464393915, 3: 0.001049111908944964}, (2, 2): {0: 0.0012991460381309601, 1: 0.007103889877855574, 2: 0.003242250972669139, 3: 0.0017481477315532234}, (2, 3): {0: -0.0035991361057733885, 1: -0.008993744705128598, 2: -0.015580713375108876, 3: 0}, (3, 0): {0: 0.01366061008886032, 1: 0, 2: 0, 3: 0.0009491454843062581}, (3, 1): {0: 0.0021459336487431573, 1: 0, 2: 0.006906126167217117, 3: 0.0010495199646256693}, (3, 2): {0: -0.009492100899205045, 1: 0, 2: -0.08035917744810732, 3: -0.0074949718755707734}, (3, 3): {0: 0.00034989501749825005, 1: 0, 2: 0.0011986210114689124, 3: 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent.value_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ_o5PNyTVXp",
        "outputId": "6173489e-3638-4aeb-c90f-cd3f894f66e3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.24505709e-02 3.98527673e-03 1.68706932e-01 2.02303786e+00]\n",
            " [2.89249578e-03 2.09616848e-03 1.26990829e-02 1.84669435e-03]\n",
            " [8.09015861e-03 1.69746395e-03 7.10388988e-03 0.00000000e+00]\n",
            " [1.36606101e-02 6.90612617e-03 0.00000000e+00 1.19862101e-03]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper Parameter 2: \n",
        "Epsilon Value: 0.4"
      ],
      "metadata": {
        "id": "-71QiLtLS0Md"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = SARSA_Agent(env, gamma=0.1, epsilon= 0.4, alpha = 0.0001)#0.4,0.8,0.01\n",
        "reward_per_episode = []\n",
        "obs = agent.reset()\n",
        "for j in range(500):\n",
        "  obs = agent.reset()\n",
        "  # x = np.random.randint(0,3)\n",
        "  # y = np.random.randint(0,3)\n",
        "  # env.agent_pos = [x,y]\n",
        "  # while(env.agent_pos[0] == 0 and env.agent_pos[1] == 3):\n",
        "  #   x = np.random.randint(0,3)\n",
        "  #   y = np.random.randint(0,3)\n",
        "  #   env.agent_pos = [x,y]\n",
        "  done = False\n",
        "  action = agent.ChooseAction(True)\n",
        "  cummulative_reward = 0\n",
        "  for i in range(15):\n",
        "    if(done == False):\n",
        "      old_state = env.agent_pos\n",
        "      observation, reward, done, _ = env.step(action)\n",
        "      new_state = env.agent_pos\n",
        "      new_action = agent.ChooseAction(True)\n",
        "      agent.Learn(old_state, action, env.immediate_reward, new_state, new_action)\n",
        "      action = new_action\n",
        "      cummulative_reward = reward\n",
        "      if(done == True):\n",
        "        print('Reward: ', env.immediate_reward)\n",
        "        print('Action: ', action)\n",
        "        print(\"Visualization Graph\")\n",
        "  reward_per_episode.append(cummulative_reward)\n",
        "\n",
        "plt.plot(reward_per_episode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wbX6sWWUTWwx",
        "outputId": "21ad9431-9ff5-4787-952d-2e3ae9fa8483"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 1. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  0\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [0 1]\n",
            "[[0.7 1.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Random Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Greedy Action\n",
            "Reward:  50\n",
            "Action:  3\n",
            "Visualization Graph\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe93d918250>]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_reward_per_episode = []\n",
        "for i in range(0,10):\n",
        "  print(\"New Episode!\")\n",
        "  agent.reset()\n",
        "  done = False\n",
        "  for j in range(0,25):\n",
        "    if(done == False):\n",
        "      print('Available Actions : ', env.getAvailableActions())\n",
        "      action = agent.ChooseAction(False)\n",
        "      observation, reward, done, _ = env.step(action)\n",
        "      print('Reward: ', reward)\n",
        "      # print('Action: ', action)\n",
        "      # print(\"Visualization Graph\")\n",
        "      # env.render()\n",
        "    else:\n",
        "      print('Goal Reached')\n",
        "      break\n",
        "    print(done)\n",
        "  total_reward_per_episode.append(reward)\n",
        "plt.plot(total_reward_per_episode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m9N_ViNZTXBH",
        "outputId": "f440adb2-6304-4984-cb26-7126f45cb3b9"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -4.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -4.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  2.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  52.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  50\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  50\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [1.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 0]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [1.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [1, 2]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -4.0\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  3.0\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  53.0\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  50\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -4.0\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  3.0\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  53.0\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Reward:  1.0\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -4.0\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  3.0\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  53.0\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -4.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -4.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  2.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  52.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  1.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 1]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  1.  0.3 0. ]]\n",
            "Reward:  0.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [3 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -4.5\n",
            "False\n",
            "Available Actions :  [1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [2 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -4.0\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [1 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  -3.5\n",
            "False\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  2.5\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  52.5\n",
            "True\n",
            "Goal Reached\n",
            "New Episode!\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Available Actions :  [0, 1, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 2]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  6\n",
            "False\n",
            "Available Actions :  [0, 2, 3]\n",
            "Greedy Action\n",
            "The Agent state is [0 3]\n",
            "[[0.7 0.  0.7 0.9]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.3]\n",
            " [0.  0.  0.3 0. ]]\n",
            "Reward:  56\n",
            "True\n",
            "Goal Reached\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe93d4954d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent.q_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG2DQPP4TYG8",
        "outputId": "b08779db-50a0-4f28-be81-e5ee6120370f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(0, 0): {0: 0, 1: 0.0358724976863038, 2: 0, 3: 0.01697197989682591}, (0, 1): {0: 0, 1: 0.000849639258951836, 2: 0.004233518361804278, 3: 0.0028926481125099964}, (0, 2): {0: 0, 1: 0.17977219511212497, 2: 0.0852372897260862, 3: 0}, (0, 3): {0: 0, 1: 0.15476772459275992, 2: 1.8259186401376302, 3: 0}, (1, 0): {0: 0.00393609274834286, 1: 0.00383666686615733, 2: 0, 3: 0.000899439834172654}, (1, 1): {0: 0.0019466303206310423, 1: 0.0015479800934895891, 2: 0.0014482866356632655, 3: 0.001597831805166194}, (1, 2): {0: 0.003043873394922006, 1: 0.013675040088347966, 2: 0.0012001111390640572, 3: 0.00030012461672700153}, (1, 3): {0: 0, 1: 0.0005497455703469804, 2: 0.0015975973742755848, 3: 0}, (2, 0): {0: 0.005819043834803309, 1: 0.005720354361675409, 2: 0, 3: 0.0018476148068850909}, (2, 1): {0: 0.006115704474627115, 1: 0.0022959408333591575, 2: 0.0020966370974165194, 3: 0.002445493224158537}, (2, 2): {0: 0.002545499279427561, 1: 0.012649493695290457, 2: 0.0012493969985091008, 3: 0.002396897786936119}, (2, 3): {0: -0.00299941205699724, 1: -0.01558079114986227, 2: -0.03231494056479886, 3: 0}, (3, 0): {0: 0.009361721141759842, 1: 0, 2: 0, 3: 0.0026431216983730872}, (3, 1): {0: 0.010396361642696321, 1: 0, 2: 0.006115599384845167, 3: 0.0025945771344357276}, (3, 2): {0: -0.023947711455705768, 1: 0, 2: -0.137111840871072, 3: -0.014482239312725003}, (3, 3): {0: 0.0012485011493677655, 1: 0, 2: 0.0015975224782030064, 3: 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent.value_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibHE0KLaSjoB",
        "outputId": "e92254e8-0361-4272-b52e-50978345902d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3.58724977e-02 4.23351836e-03 1.79772195e-01 1.82591864e+00]\n",
            " [3.93609275e-03 1.94663032e-03 1.36750401e-02 1.59759737e-03]\n",
            " [5.81904383e-03 6.11570447e-03 1.26494937e-02 0.00000000e+00]\n",
            " [9.36172114e-03 1.03963616e-02 0.00000000e+00 1.59752248e-03]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "References"
      ],
      "metadata": {
        "id": "_wZENhbzvyC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1) CSE 574 - Prof. Alina's Code\n",
        "#2) https://www.youtube.com/watch?v=2-OljVM15gc&t=208s"
      ],
      "metadata": {
        "id": "i0cva5mJvzYf"
      },
      "execution_count": 59,
      "outputs": []
    }
  ]
}